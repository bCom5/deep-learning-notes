<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js ayu">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>CS 282: Deep Learning Notes Spring 2020</title>
        
        <meta name="robots" content="noindex" />
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:500" rel="stylesheet" type="text/css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "ayu" : "ayu";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('ayu')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div id="sidebar-scrollbox" class="sidebar-scrollbox">
                <ol class="chapter"><li class="expanded "><a href="introduction.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="expanded "><a href="lectures/lectures.html"><strong aria-hidden="true">2.</strong> Lectures</a></li><li><ol class="section"><li class="expanded "><a href="lectures/lec09_rnn.html"><strong aria-hidden="true">2.1.</strong> Recurrent Networks, LSTMS, and Applications</a></li><li class="expanded "><a href="lectures/lec10_visual.html"><strong aria-hidden="true">2.2.</strong> Visualizing Deep Networks</a></li><li class="expanded "><a href="lectures/lec11_attention.html"><strong aria-hidden="true">2.3.</strong> Attention Networks</a></li><li class="expanded "><a href="lectures/lec12_text_semantics.html"><strong aria-hidden="true">2.4.</strong> Text Semantics</a></li><li class="expanded "><a href="lectures/lec13_translation.html"><strong aria-hidden="true">2.5.</strong> Translation</a></li><li class="expanded "><a href="lectures/lec14_transformers.html"><strong aria-hidden="true">2.6.</strong> Transformers and Pre-Training</a></li><li class="expanded "><a href="lectures/lec15_nlp_applications.html"><strong aria-hidden="true">2.7.</strong> NLP Applications</a></li><li class="expanded "><a href="lectures/lec16_generative_models.html"><strong aria-hidden="true">2.8.</strong> Generative Models</a></li><li class="expanded "><a href="lectures/lec17_gan.html"><strong aria-hidden="true">2.9.</strong> Generative Adversarial Networks</a></li><li class="expanded "><a href="lectures/lec18_adversarial_networks.html"><strong aria-hidden="true">2.10.</strong> Adversarial Networks</a></li><li class="expanded "><a href="lectures/lec19_fairness.html"><strong aria-hidden="true">2.11.</strong> Fairness in Deep Learning</a></li><li class="expanded "><a href="lectures/lec20_imitation_learning.html"><strong aria-hidden="true">2.12.</strong> Imitation Learning</a></li><li class="expanded "><a href="lectures/lec21_rl_policy_gradients.html"><strong aria-hidden="true">2.13.</strong> Reinforcement Learning: Policy Gradients</a></li><li class="expanded "><a href="lectures/lec22_deep_rl_value_based.html"><strong aria-hidden="true">2.14.</strong> Deep RL: Value-Based Methods</a></li><li class="expanded "><a href="lectures/lect23_exploration.html"><strong aria-hidden="true">2.15.</strong> Exploration</a></li></ol></li><li class="expanded "><a href="other_resources/other_resources.html"><strong aria-hidden="true">3.</strong> Other Resources</a></li><li><ol class="section"><li class="expanded "><a href="other_resources/viz_seq.html"><strong aria-hidden="true">3.1.</strong> Visualizing Seq2Seq with Attention</a></li><li class="expanded "><a href="other_resources/viz_transformers.html"><strong aria-hidden="true">3.2.</strong> Visualizing Transformers</a></li><li class="expanded "><a href="other_resources/viz_bert_elmo_gpt.html"><strong aria-hidden="true">3.3.</strong> Visualizing BERT, ELMo, and GPT</a></li><li class="expanded "><a href="other_resources/review_cs188.html"><strong aria-hidden="true">3.4.</strong> Review CS 188: AI</a></li></ol></li><li class="expanded "><a href="homework/homework.html"><strong aria-hidden="true">4.</strong> Homeworks</a></li><li><ol class="section"><li class="expanded "><a href="homework/hw2_rnn_lstm.html"><strong aria-hidden="true">4.1.</strong> Homework 2 RNN and LSTM</a></li><li class="expanded "><a href="homework/hw3_nlp.html"><strong aria-hidden="true">4.2.</strong> Homework 3 Natural Language Processing</a></li></ol></li><li class="expanded "><a href="section/section.html"><strong aria-hidden="true">5.</strong> Section</a></li><li><ol class="section"><li class="expanded "><a href="section/sect5.html"><strong aria-hidden="true">5.1.</strong> Section 5: Attention Mechanisms and Transformers</a></li><li class="expanded "><a href="section/sect6.html"><strong aria-hidden="true">5.2.</strong> Section 6: Transformers and Pretraining in NLP</a></li><li class="expanded "><a href="section/sect7.html"><strong aria-hidden="true">5.3.</strong> Section 7: Fooling Networks and Generative Models</a></li><li class="expanded "><a href="section/sect8.html"><strong aria-hidden="true">5.4.</strong> Section 8: Fairness, MDP, Imitation Learning</a></li></ol></li><li class="expanded "><a href="project/project.html"><strong aria-hidden="true">6.</strong> Final Project: Model Distillation Low Precision Neural Networks</a></li><li><ol class="section"><li class="expanded "><a href="project/xnor-net.html"><strong aria-hidden="true">6.1.</strong> XNOR-net</a></li><li class="expanded "><a href="project/knowledge_distill.html"><strong aria-hidden="true">6.2.</strong> Knowledge Distillation</a></li><li class="expanded "><a href="project/dorefa_net.html"><strong aria-hidden="true">6.3.</strong> DoReFa-Net</a></li><li class="expanded "><a href="project/apprentice_knowledge_distill.html"><strong aria-hidden="true">6.4.</strong> Apprentice: Knowledge Distillation with Low-Precision Networks</a></li><li class="expanded "><a href="project/ta.html"><strong aria-hidden="true">6.5.</strong> Improved Knowledge Distillation via Teacher Assistant</a></li><li class="expanded "><a href="project/ta_code.html"><strong aria-hidden="true">6.6.</strong> Teacher Assistant Code</a></li></ol></li><li class="expanded "><a href="exam/exam.html"><strong aria-hidden="true">7.</strong> Exam Practice</a></li><li><ol class="section"><li class="expanded "><a href="exam/midterm1/midterm1.html"><strong aria-hidden="true">7.1.</strong> Midterm 1</a></li><li><ol class="section"><li class="expanded "><a href="exam/midterm1/mt1sp19.html"><strong aria-hidden="true">7.1.1.</strong> Midterm 1 Spring 2019</a></li><li class="expanded "><a href="exam/midterm1/mt1prac1sp18.html"><strong aria-hidden="true">7.1.2.</strong> Midterm 1 Practice 1 Spring 2018</a></li><li class="expanded "><a href="exam/midterm1/cheatsheet.html"><strong aria-hidden="true">7.1.3.</strong> Midterm 1 Cheat Sheet</a></li></ol></li><li class="expanded "><a href="exam/quiz1/quiz1.html"><strong aria-hidden="true">7.2.</strong> Take Home Quiz 1</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar" class="menu-bar">
                    <div id="menu-bar-sticky-container">
                        <div class="left-buttons">
                            <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                                <i class="fa fa-bars"></i>
                            </button>
                            <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                                <i class="fa fa-paint-brush"></i>
                            </button>
                            <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                                <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu (default)</button></li>
                            </ul>
                            
                            <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                                <i class="fa fa-search"></i>
                            </button>
                            
                        </div>

                        <h1 class="menu-title">CS 282: Deep Learning Notes Spring 2020</h1>

                        <div class="right-buttons">
                            <a href="print.html" title="Print this book" aria-label="Print this book">
                                <i id="print-button" class="fa fa-print"></i>
                            </a>
                            
                        </div>
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#introduction" id="introduction">Introduction</a></h1>
<p>CS 282 Deep Learning, Spring 2020 
Taught by John Canny</p>
<p><img src="https://i.imgur.com/0ztiyxz.png" alt="" /></p>
<ul>
<li><a href="https://bcourses.berkeley.edu/courses/1487769">Website</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLkFD6_40KJIwaO6Eca8kzsEFBob0nFvwm">Webcast</a></li>
</ul>
<h1><a class="header" href="#lectures" id="lectures">Lectures</a></h1>
<h1><a class="header" href="#recurrent-networks-lstms-and-applications" id="recurrent-networks-lstms-and-applications">Recurrent Networks, LSTMS, and Applications</a></h1>
<h1><a class="header" href="#visualizing-deep-networks" id="visualizing-deep-networks">Visualizing Deep Networks</a></h1>
<h3><a class="header" href="#activation-maximization" id="activation-maximization">Activation Maximization</a></h3>
<p><img src="https://i.imgur.com/bKFfWQy.png" alt="" /></p>
<p>Generate a synthetic image I, normalize it L2 nrom, maxing a class. This is done through backpropogation. Class is one hot encoded <code>[0 0 1 0 0]</code>. Images are weird though.</p>
<h3><a class="header" href="#deconv-approaches" id="deconv-approaches">Deconv Approaches</a></h3>
<p><img src="https://i.imgur.com/L9W4AWf.png" alt="" /></p>
<p>To make generating synthetic images better:</p>
<ul>
<li>backprop zeros out negative values in the forward pass</li>
<li>decovnet zeros out negative gradients in the backward pass. Negative gradients are inhibitory activations (they were the wrong class)</li>
<li>guided backprop does both, zeros out both</li>
</ul>
<h3><a class="header" href="#neural-style-transfer" id="neural-style-transfer">Neural Style Transfer</a></h3>
<p><img src="https://i.imgur.com/xdURQhp.jpg" alt="" /></p>
<p>Review this!</p>
<h1><a class="header" href="#attention-networks" id="attention-networks">Attention Networks</a></h1>
<p><strong>The most important idea in deep networks this decade.</strong></p>
<h3><a class="header" href="#pilot-analogy" id="pilot-analogy">Pilot analogy</a></h3>
<p><img src="https://i.imgur.com/LU12T8h.jpg" alt="" /></p>
<p>Pilots move their focus on different things, gauges, buttons, switches</p>
<h3><a class="header" href="#papers" id="papers">Papers</a></h3>
<p>Attention is All You Need (2017) only stacked attention, previous used RNNs</p>
<h2><a class="header" href="#soft-vs-hard-attention-introduction" id="soft-vs-hard-attention-introduction">Soft vs Hard Attention Introduction</a></h2>
<p><img src="https://i.imgur.com/GwTuFpG.png" alt="" /></p>
<ul>
<li><strong>Hard Attention</strong> is what humans do. Not differentiable because attention map is 1 where focused, 0 elsewhere (discrete).</li>
<li><strong>Soft Attention</strong> - linear combination over inputs, can use backprop.
<ul>
<li>Trains network and attention to the right place!</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/3JN8VEn.png" alt="" />
<strong>Supervised Learning</strong> vs <strong>Reinforcement Learning</strong>, maximizing a reward (discrete)</p>
<p>Reinforcement Learning, the <strong>agent tries to maximize the sum of rewards over an epoch</strong></p>
<h2><a class="header" href="#attention-for-recognition" id="attention-for-recognition">Attention for Recognition</a></h2>
<p><img src="https://i.imgur.com/d2tfdX3.png" alt="" /></p>
<p>Has time stamps. Has location and the image. RNN always predicting gaze location for next time.</p>
<p><img src="https://i.imgur.com/BAmjvmm.png" alt="" /></p>
<p>Resolution when focusing on something (glimpse). Output is location and action (classify/don't classify). Inputs are on top, output is at the bottom.</p>
<p><img src="https://i.imgur.com/NnoPB1G.png" alt="" /></p>
<p>This shows glimpses. Focused in center. Blurred around. More blurred after, 3 levels. Green is location as it moves around.</p>
<h2><a class="header" href="#soft-attention-for-translation" id="soft-attention-for-translation">Soft Attention for Translation</a></h2>
<p><img src="https://i.imgur.com/ode4uKw.png" alt="" /></p>
<p>When the world is outputting <em>Me</em>, it has attention on <em>I</em>. Likewise with <em>coffee</em> and <em>cafe</em>.</p>
<p><img src="https://i.imgur.com/bWX5rXq.png" alt="" /></p>
<p>What word does each word correspond to? (Where is the attention located)?</p>
<h2><a class="header" href="#rnn-for-captioning" id="rnn-for-captioning">RNN for Captioning</a></h2>
<p><img src="https://i.imgur.com/O3QzfWP.png" alt="" /></p>
<p>Output <code>d0</code> goes into a softmax over the vocabulary. <em>Bird</em> is fed back into <code>x1</code>, next token. </p>
<p><img src="https://i.imgur.com/qA37EVl.png" alt="" /></p>
<p>Have \( L \times D \) features extracted. Our RNN outputs classification and weight location. Mask/summing (?) with the features give the weighted feature \( D \) fed back into the RNN.</p>
<h2><a class="header" href="#soft-vs-hard-attention-in-captioning" id="soft-vs-hard-attention-in-captioning">Soft vs. Hard Attention in Captioning</a></h2>
<p><img src="https://i.imgur.com/VNdA0yR.png" alt="" /></p>
<ul>
<li>Have two inputs, RNN gives probability distribution (see above) (also think about the result of softmax).</li>
<li><strong>Soft Attention</strong> sum all location and derivative is \( \frac{dz}{dp} \). Train with gradient descent.</li>
<li><strong>Hard Attention</strong> samples only one location. With argmax, \( \frac{dz}{dp} \) is almost zero everywhere. Can't use gradient descent.</li>
</ul>
<p><img src="https://i.imgur.com/RphCcoj.png" alt="" /></p>
<p>Soft is smooth around the area. Hard is discrete (1 or 0) around the image.</p>
<p><img src="https://i.imgur.com/wLcn23X.jpg" alt="" /></p>
<p><img src="https://i.imgur.com/YYT5G2u.jpg" alt="" /></p>
<p>Can see where it made mistakes!!!</p>
<h2><a class="header" href="#attention-mechanics" id="attention-mechanics">Attention Mechanics</a></h2>
<p><img src="https://i.imgur.com/0q6PVTx.png" alt="" /></p>
<ul>
<li>Image Feature output matrix \( L \times D \)</li>
<li>Attention weights output vector \( L \). Can \( L \) be an image \( H \times W \)?</li>
<li>Do a broadcast multiply - each vector in \( D \) multiplies by the Attention vector. Output is still \( L \times D \)</li>
<li>Sum the \( L \) axis (vector). Output is size \( D \).</li>
</ul>
<p><img src="https://i.imgur.com/NcPqXPf.png" alt="" /></p>
<ul>
<li>Need sum for the contributions. This is because \( B \) is broadcast multiplied to \( A \)</li>
</ul>
<h3><a class="header" href="#salience" id="salience">Salience</a></h3>
<p><img src="https://i.imgur.com/v4cwBwH.png" alt="" /></p>
<ul>
<li>Circle operation is product</li>
<li>What is salience (A *dot* )
<ul>
<li><strong>Salience:</strong> The total contribution and gradient to the output (the importance of an area)</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#attention-and-lstm" id="attention-and-lstm">Attention and LSTM</a></h2>
<p><img src="https://i.imgur.com/EDcAoA5.png" alt="" /></p>
<ul>
<li>LSTMs also receive a <strong>salience gradient</strong>. There is multiplicative gating (kind of like attention)</li>
</ul>
<h2><a class="header" href="#soft-attention-for-video" id="soft-attention-for-video">Soft Attention for Video</a></h2>
<p><img src="https://i.imgur.com/wHL1iwj.png" alt="" /></p>
<p>Now temporal (time) can have attention. (Which frame is important?)</p>
<p><img src="https://i.imgur.com/lo2rgUy.png" alt="" /></p>
<ul>
<li>Can have spatial and temporal attention. Temporal in this network.</li>
<li>Create a vector of feature frames.</li>
</ul>
<p><img src="https://i.imgur.com/uvLw16A.png" alt="" /></p>
<p><img src="https://i.imgur.com/iNBaAPT.png" alt="" /></p>
<p>Perplexity is diversity of word options. Goal is smaller which means the model is more confident.</p>
<h2><a class="header" href="#find-the-region-again" id="find-the-region-again">Find the Region Again</a></h2>
<p><img src="https://i.imgur.com/gVzxWMc.png" alt="" /></p>
<ul>
<li>Classify - attention to regions in input</li>
<li>Generate - draw digit</li>
</ul>
<p>Has a parameter for scale</p>
<h2><a class="header" href="#takeaways" id="takeaways">Takeaways</a></h2>
<p><img src="https://i.imgur.com/vquu8LF.png" alt="" /></p>
<ul>
<li><strong>Salience:</strong> Emphasize imporant data.</li>
</ul>
<p><img src="https://i.imgur.com/ddEkm4X.png" alt="" /></p>
<h1><a class="header" href="#text-semantics" id="text-semantics">Text Semantics</a></h1>
<p><a href="https://youtu.be/1rzjaUp6NiQ">Webcast</a></p>
<p><img src="https://i.imgur.com/7LIXXrJ.png" alt="" /></p>
<ul>
<li><strong>Propositional</strong>: logic, formal, mathematical</li>
<li><strong>Vector</strong>: represent as numbers, high dimensional space.</li>
</ul>
<p><img src="https://i.imgur.com/br0ryjb.png" alt="" /></p>
<ul>
<li>Propositional uses class (usually noun) and predicates - operation (usually a verb). <strong>Reasoning</strong></li>
<li>Word and sentences represented as vectors. Commutative! That is a problem.</li>
</ul>
<h2><a class="header" href="#vector-embedding-of-words" id="vector-embedding-of-words">Vector Embedding of Words</a></h2>
<p><img src="https://i.imgur.com/CGwXg4v.png" alt="" /></p>
<ul>
<li><strong>Bag-of-Words</strong> - sentence</li>
</ul>
<h3><a class="header" href="#word-similarity" id="word-similarity">Word Similarity</a></h3>
<p><img src="https://i.imgur.com/Vd6TRq8.png" alt="" /></p>
<ul>
<li><strong>Similar word</strong> in <strong>similar contexts</strong>. Dog and canine can be replaced.</li>
</ul>
<p><img src="https://i.imgur.com/Nqc0KTP.png" alt="" /></p>
<h3><a class="header" href="#dimension-reduction" id="dimension-reduction">Dimension Reduction</a></h3>
<p><img src="https://i.imgur.com/L54iu21.png" alt="" /></p>
<ul>
<li>Could <strong>one-hot encode</strong> every word in vocab. That's expensive.</li>
<li>Alt: counts of word used in that context. &quot;Dog barks&quot;.</li>
</ul>
<h2><a class="header" href="#dimensionality-reduction" id="dimensionality-reduction">Dimensionality Reduction</a></h2>
<p><img src="https://i.imgur.com/sd6BKtO.png" alt="" /></p>
<h3><a class="header" href="#latent-semantic-analysis" id="latent-semantic-analysis">Latent Semantic Analysis</a></h3>
<p><img src="https://i.imgur.com/YogMF8j.png" alt="" /></p>
<ul>
<li>Encode documents <code>N</code></li>
<li><code>M</code> is word count.</li>
</ul>
<p><img src="https://i.imgur.com/hXnjAO7.png" alt="" /></p>
<p>Counts words</p>
<h3><a class="header" href="#latent-semantic-analysis-1" id="latent-semantic-analysis-1">Latent Semantic Analysis</a></h3>
<p><img src="https://i.imgur.com/QEJ4hZq.png" alt="" /></p>
<ul>
<li>Low dimensional approximation using SVD. (Review SVD!)</li>
<li>Embedding is V, factors encode document contexts</li>
</ul>
<h4><a class="header" href="#singular-value-decomposition" id="singular-value-decomposition">Singular Value Decomposition</a></h4>
<p><img src="https://i.imgur.com/8vySkwT.png" alt="" /></p>
<ul>
<li>\( U, V \) <strong>orthogonal, normal</strong>. \( S \) rectangular diagonal, singular values, right padded with 0s to fit</li>
</ul>
<h4><a class="header" href="#review-how-to-calculate-svd" id="review-how-to-calculate-svd">Review How to Calculate SVD</a></h4>
<p><img src="https://i.imgur.com/VHinLAL.png" alt="" /></p>
<ul>
<li>It can be computed from eigenvalues of \( T ~ T ^T \)</li>
<li>Insides cancel out, there's an \( S^2 \) term!!!</li>
</ul>
<p><img src="https://i.imgur.com/FB3xuv1.png" alt="" /></p>
<p>Both work!</p>
<p><img src="https://i.imgur.com/2ynYgmd.png" alt="" /></p>
<ul>
<li>Can have a smaller S, using only the largest singular values (S?) </li>
<li>Small K dimension</li>
<li>High dimensional T to low dimensional </li>
<li><strong>best possible reconstruction</strong> of documents from their embedding</li>
</ul>
<p><img src="https://i.imgur.com/mWKPVXo.png" alt="" /></p>
<ul>
<li>Documents are T, Encoding is Z</li>
</ul>
<p><img src="https://i.imgur.com/0IJVSaK.png" alt="" /></p>
<ul>
<li>Have a network learn SVD</li>
<li>V is vocab times latent dimensions</li>
<li>Scalable version of LSA/SVD</li>
<li>similar things will get mapped to similar places</li>
</ul>
<h2><a class="header" href="#t-sne-word-embeddings" id="t-sne-word-embeddings">t-SNE Word Embeddings</a></h2>
<p><img src="https://i.imgur.com/tF1VGAF.png" alt="" /></p>
<h2><a class="header" href="#word2vec" id="word2vec">Word2Vec</a></h2>
<p><img src="https://i.imgur.com/LmTf2z2.png" alt="" /></p>
<ul>
<li>neighborhood of a word instead of whole document, <strong>skip-gram</strong></li>
<li>nonlinearity</li>
</ul>
<p><img src="https://i.imgur.com/GLAWU4T.png" alt="" /></p>
<ul>
<li>Predict center words from context</li>
<li>order does not matter</li>
</ul>
<p><img src="https://i.imgur.com/ZrKymNE.png" alt="" /></p>
<ul>
<li>Predict context words from center word</li>
</ul>
<p><img src="https://i.imgur.com/9sTa45d.png" alt="" /></p>
<ul>
<li>Problem of SVD is it favors minimizing large distances (min squared error). Want to preserve <strong>close</strong> distance like t-SNE</li>
</ul>
<p><img src="https://i.imgur.com/E3M523Q.png" alt="" /></p>
<ul>
<li>Canny says it's a mess</li>
</ul>
<p><img src="https://i.imgur.com/29fFUrk.png" alt="" /></p>
<ul>
<li>Holds relations as vectors! Vector math!</li>
</ul>
<p><img src="https://i.imgur.com/0WFGMaA.png" alt="" /></p>
<ul>
<li>This model uses contexts</li>
<li>City pairs, opposites, comparatives (great, greater)</li>
</ul>
<p>Criticisms:</p>
<ul>
<li>Cross-entropy emphasizes small word combinations</li>
<li>Expensive to softmax</li>
</ul>
<p><img src="https://i.imgur.com/Er3Ogvq.png" alt="" /></p>
<ul>
<li>Maybe wrong data</li>
</ul>
<p><img src="https://i.imgur.com/CwVSFNj.png" alt="" /></p>
<ul>
<li>Now words times words! Better for contextual words!</li>
<li>Window size (prob exam problem), just try it and check</li>
</ul>
<h2><a class="header" href="#glove" id="glove">GloVe</a></h2>
<p><img src="https://i.imgur.com/OkSCRaK.png" alt="" /></p>
<ul>
<li>\( C_{ij} \) num times word j in context of word i. Query the matrix
<ul>
<li>For favoring the counts</li>
</ul>
</li>
<li>\( u_i \) is embedding, \( v_j \) is context word embedding
<ul>
<li>Inner product for similarity!!!</li>
</ul>
</li>
<li>\( f \) properties make it small for close words, and not too big for unlike words in context</li>
</ul>
<p><img src="https://i.imgur.com/CJ0MNrE.png" alt="" /></p>
<h2><a class="header" href="#compositional-semantics" id="compositional-semantics">Compositional Semantics</a></h2>
<p><img src="https://i.imgur.com/NsrUYj7.png" alt="" /></p>
<ul>
<li><strong>Compositional Semantics</strong> capture meaning in the structure and ordering </li>
</ul>
<p><img src="https://i.imgur.com/H4Iio7l.png" alt="" /></p>
<h3><a class="header" href="#skip-through-vectors" id="skip-through-vectors">Skip-Through Vectors</a></h3>
<p><img src="https://i.imgur.com/3TYFBkQ.png" alt="" /></p>
<ul>
<li>Predict the previous sentence and next sentences
<ul>
<li>Fed back in</li>
</ul>
</li>
<li>RNN, each state </li>
</ul>
<p><img src="https://i.imgur.com/ozMrn5g.png" alt="" /></p>
<ul>
<li>Doesn't require backprop?</li>
</ul>
<p><img src="https://i.imgur.com/VCd42TW.png" alt="" /></p>
<ul>
<li>Human evaluation.</li>
</ul>
<p><img src="https://i.imgur.com/LS5i6O1.png" alt="" /></p>
<ul>
<li>Why not just train/optimize for similarity
<ul>
<li>Minimize Manhattan distance</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#semantic-entailment-evaluation" id="semantic-entailment-evaluation">Semantic Entailment Evaluation</a></h3>
<p><img src="https://i.imgur.com/pHYzAi9.png" alt="" /></p>
<ul>
<li>Tasks are Entailment, Contradiction, Neutral</li>
</ul>
<h1><a class="header" href="#translation" id="translation">Translation</a></h1>
<ul>
<li><a href="https://briantliao.com/store/cs282-lectures-slides/lec13.pdf">Slides</a></li>
</ul>
<h2><a class="header" href="#review" id="review">Review</a></h2>
<p><img src="https://i.imgur.com/ytGyXuo.png" alt="" /></p>
<ul>
<li>Inner Product (or is it Dot Product?) is closeness</li>
</ul>
<p><img src="https://i.imgur.com/E9DMaxX.png" alt="" /></p>
<ul>
<li>Predict previous and next sentences, now ordering is included</li>
</ul>
<p><img src="https://i.imgur.com/r9NLuPf.png" alt="" /></p>
<ul>
<li>Train for your task! This is based on closeness.</li>
</ul>
<h2><a class="header" href="#translation-1" id="translation-1">Translation</a></h2>
<p><img src="https://i.imgur.com/myVDtam.png" alt="" /></p>
<h3><a class="header" href="#sequence-to-sequence" id="sequence-to-sequence">Sequence to Sequence</a></h3>
<ul>
<li><strong>Sequence-To-Sequence RNN</strong>, input fed into left, output comes out of the right</li>
</ul>
<p><img src="https://i.imgur.com/3HwFFEZ.png" alt="" /></p>
<ul>
<li>At each RNN node, the output is fed back in. Keep the n-best</li>
</ul>
<h3><a class="header" href="#bleu" id="bleu">Bleu</a></h3>
<p><img src="https://i.imgur.com/9G6bB4e.png" alt="" /></p>
<ul>
<li>Candidate is what our network gives us. References are from humans.</li>
<li>See where it matches.</li>
</ul>
<p><img src="https://i.imgur.com/1lMHytF.png" alt="" /></p>
<ul>
<li>Unigram matching - mapping</li>
</ul>
<p><img src="https://i.imgur.com/j2kCRM2.png" alt="" /></p>
<ul>
<li>Averaged over references</li>
</ul>
<p><img src="https://i.imgur.com/IyG2pdL.png" alt="" /></p>
<ul>
<li><strong>Unigram</strong> for <strong>adequacy</strong></li>
<li><strong>Ngram</strong> for <strong>fluency</strong>
<ul>
<li>Fluency is better (imo)</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/j4kbkLo.png" alt="" /></p>
<ul>
<li>Bigram (2 word length)</li>
</ul>
<p><img src="https://i.imgur.com/P9iowOf.png" alt="" /></p>
<ul>
<li>Geometric Avg ( (( w_n log p_n \) )
<ul>
<li>BP: penalty shorter than r</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/4xTSym1.png" alt="" /></p>
<ul>
<li>Ensemble does well</li>
</ul>
<p><img src="https://i.imgur.com/4dQNLlc.png" alt="" /></p>
<ul>
<li>Try going backwards!
<ul>
<li>coffee love I</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/EC4HORT.png" alt="" /></p>
<ul>
<li>Really small BEAM search</li>
</ul>
<p><img src="https://i.imgur.com/tJE0USb.png" alt="" /></p>
<ul>
<li>Problem! There's a bottleneck for information</li>
</ul>
<p><img src="https://i.imgur.com/qERSjqN.png" alt="" /></p>
<ul>
<li>In soft-attention, Coffee is related to cafe
<ul>
<li>But bottlenecked!</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#soft-attention-for-translation-1" id="soft-attention-for-translation-1">Soft Attention for Translation</a></h2>
<p><img src="https://i.imgur.com/ZETrFIt.png" alt="" /></p>
<ul>
<li><strong>Context vector</strong> is the sum of all weighed h, which are hidden states</li>
<li>Weights are <strong>Mixture weights</strong>, softmax over alignment scores</li>
<li><strong>Alignment scores</strong> input words and output words?</li>
</ul>
<p><img src="https://i.imgur.com/YPalgse.png" alt="" /></p>
<ul>
<li>Wow this is amazing</li>
<li>Bi-directional RNN Encoder</li>
</ul>
<p><img src="https://i.imgur.com/Z1r7qjJ.png" alt="" /></p>
<ul>
<li>Decoder is a RNN, sample word fed back in, get next word out</li>
<li>You have a <strong>Recurrent State</strong> in the <strong>Decoder RNN</strong></li>
<li>and a <strong>Attention Vectors</strong> hidden state in the <strong>Bidirection Encoder RNN</strong></li>
</ul>
<p><img src="https://i.imgur.com/RFYS1Xt.png" alt="" /></p>
<p><img src="https://i.imgur.com/nl7EEHM.png" alt="" /></p>
<ul>
<li>English to French, correctly picks up reversal!</li>
</ul>
<p><img src="https://i.imgur.com/EF8asQs.png" alt="" /></p>
<ul>
<li><strong>Neural Machine Translation!</strong>
<ul>
<li>Complicated model, what the heck</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#stanford-manning-update-attention-neural-machine-translation" id="stanford-manning-update-attention-neural-machine-translation">Stanford Manning Update Attention Neural Machine Translation</a></h3>
<p><img src="https://i.imgur.com/LU9UKYM.png" alt="" /></p>
<ul>
<li>Stacked LSTM</li>
</ul>
<p><img src="https://i.imgur.com/GyKZ5bK.png" alt="" /></p>
<ul>
<li><strong>Global Attention</strong>, Attention is not Recurrent, align weights are now global</li>
</ul>
<p><img src="https://i.imgur.com/4AXBT7p.png" alt="" /></p>
<ul>
<li>Alignment (?)</li>
</ul>
<h3><a class="header" href="#translation-and-parsing" id="translation-and-parsing">Translation and Parsing</a></h3>
<p><img src="https://i.imgur.com/EqGiSWf.png" alt="" /></p>
<ul>
<li>Can generate like nested/tree code!</li>
</ul>
<p><img src="https://i.imgur.com/I2NfCBU.png" alt="" /></p>
<ul>
<li>Build the parse tree (Nouns, parts, etc.)
<ul>
<li>Trees are like LISP, can be nested in parenthesis</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/u5gQqQI.png" alt="" /></p>
<ul>
<li>Sequence-To-Sequence Parse Tree</li>
</ul>
<p><img src="https://i.imgur.com/SBY9QQq.png" alt="" /></p>
<ul>
<li>Training, on the three-bank not well</li>
<li>Then train on the Berkeley Parser</li>
<li>Add attention and retrain on human data
<ul>
<li>It's like Model Distillation?</li>
<li>Something about overfitting</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#attention-only-translation" id="attention-only-translation">Attention-only Translation</a></h2>
<p><img src="https://i.imgur.com/wNITJAH.png" alt="" /></p>
<ul>
<li>Time grows in proportion to sentence length</li>
<li>Long-range hard</li>
<li>Hierarchal deeper structure hard</li>
</ul>
<h3><a class="header" href="#transformer" id="transformer">Transformer</a></h3>
<p><img src="https://i.imgur.com/YJD3LBN.png" alt="" /></p>
<ul>
<li>Query-Key-Value</li>
</ul>
<p><img src="https://i.imgur.com/ki9Z54a.png" alt="" /></p>
<ul>
<li>Try my query to other keys</li>
</ul>
<p><img src="https://i.imgur.com/ctviBRe.png" alt="" /></p>
<ul>
<li>Score is local, Softmax x Value then Sum is global</li>
</ul>
<p><img src="https://i.imgur.com/079hOLX.png" alt="" /></p>
<ul>
<li>Input x, compute inner products with their matrices
<ul>
<li>\( W^V, W^K, W^Q \)</li>
<li>Get \( V_1, K_1, Q_1 \)</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/3Xd2tFj.png" alt="" /></p>
<p><img src="https://i.imgur.com/SUfx7a8.png" alt="" /></p>
<ul>
<li>Q, K, V are matrices now</li>
</ul>
<p><img src="https://i.imgur.com/qzELmTE.png" alt="" /></p>
<ul>
<li><strong>Multi-Headed Attention</strong></li>
</ul>
<p><img src="https://i.imgur.com/14NfcZi.png" alt="" /></p>
<ul>
<li>multiple heads
<ul>
<li>recognized more difficult is coupled</li>
<li>blue, green, red</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/sPO4eMU.png" alt="" /></p>
<ul>
<li><strong>Transformer Encoder</strong>
<ul>
<li>Encoded as a single matrix</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/jTD6Qo6.png" alt="" /></p>
<h4><a class="header" href="#transformer-encoderdecoder" id="transformer-encoderdecoder">Transformer Encoder/Decoder</a></h4>
<p><img src="https://i.imgur.com/IKZ7vfD.png" alt="" /></p>
<ul>
<li>Value Key fed in</li>
</ul>
<p><img src="https://i.imgur.com/wZmiJ9e.png" alt="" /></p>
<h1><a class="header" href="#transformers-and-pre-training" id="transformers-and-pre-training">Transformers and Pre-Training</a></h1>
<p><a href="https://towardsdatascience.com/visual-attention-model-in-deep-learning-708813c2912c">Visual Attention</a></p>
<p><a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">Visualizing NMT</a></p>
<p><a href="http://jalammar.github.io/illustrated-transformer/">Visualizing Transformers</a></p>
<h2><a class="header" href="#review-1" id="review-1">Review</a></h2>
<p><img src="https://i.imgur.com/BVdVEoi.png" alt="" /></p>
<ul>
<li>Up and Down Attention</li>
</ul>
<p><img src="https://i.imgur.com/gGG4J6N.png" alt="" /></p>
<ul>
<li>Transformers (Convolution of NLP)
<ul>
<li>Self Attention</li>
<li>Encoding/Decoding</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#transformers" id="transformers">Transformers</a></h2>
<p><img src="https://i.imgur.com/mYSymyv.png" alt="" /></p>
<p><img src="https://i.imgur.com/5jvchbe.png" alt="" /></p>
<ul>
<li><strong>Multi-Headed Attention</strong>
<code>h</code> block of scaled dot-product attention. Tensor V, K, Q</li>
</ul>
<p><img src="https://i.imgur.com/aqMQVVh.png" alt="" /></p>
<ul>
<li>What is Encoder/Decoder?</li>
</ul>
<h3><a class="header" href="#transformer-encoder" id="transformer-encoder">Transformer Encoder</a></h3>
<p><img src="https://i.imgur.com/Bd6mOCq.png" alt="" /></p>
<ul>
<li>Has residuals of based inputs</li>
<li>What is the Positional Encoding</li>
</ul>
<p><img src="https://i.imgur.com/FmYWjJH.png" alt="" /></p>
<p><img src="https://i.imgur.com/0dTtfWA.png" alt="" /></p>
<ul>
<li>Why does it mix?</li>
<li>From words and has positional encoding</li>
</ul>
<h3><a class="header" href="#multi-headed-attention" id="multi-headed-attention">Multi-Headed Attention</a></h3>
<p><img src="https://i.imgur.com/LgGrwEe.png" alt="" /></p>
<ul>
<li>Attention strength (sum) from different words</li>
</ul>
<p><img src="https://i.imgur.com/G490xoJ.png" alt="" /></p>
<ul>
<li>Self Attention (?)</li>
<li>What are the colors of the lines and on the words (?)</li>
</ul>
<h3><a class="header" href="#transformer-decoding" id="transformer-decoding">Transformer Decoding</a></h3>
<p><img src="https://i.imgur.com/J7O9jOG.png" alt="" /></p>
<ul>
<li>Decoding is to generate text</li>
<li>Attention vs Self-Attention (?)</li>
<li>What does the direction of the arrow mean?</li>
</ul>
<p><img src="https://i.imgur.com/IVhfqGJ.png" alt="" /></p>
<ul>
<li>Green is (causal/masked) self-attention</li>
</ul>
<p><img src="https://i.imgur.com/NAR824z.png" alt="" /></p>
<ul>
<li>At training time can do in parallel</li>
</ul>
<p><img src="https://i.imgur.com/7byCbh7.png" alt="" /></p>
<ul>
<li>N-Best Transformers, k copy of your output word
<ul>
<li>renard with 0.3 confidence</li>
<li>canard with 0.1 confidence</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#transformer-position-encoding" id="transformer-position-encoding">Transformer Position Encoding</a></h3>
<p><img src="https://i.imgur.com/vfl5qkP.png" alt="" /></p>
<ul>
<li>The encoding doesn't have any ordering</li>
<li>Position is a sinusoid?</li>
</ul>
<p><img src="https://i.imgur.com/AguYmZQ.png" alt="" /></p>
<ul>
<li>If your vector is even or odd
<ul>
<li>Learnable shifting relative displacement</li>
<li>The inner product measures relative displacement</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/l2zCU1J.png" alt="" /></p>
<p><img src="https://i.imgur.com/oWqORx5.png" alt="" /></p>
<ul>
<li>linear combination that is strongest at position (idk)</li>
</ul>
<h2><a class="header" href="#tokenization-challenges" id="tokenization-challenges">Tokenization Challenges</a></h2>
<p><img src="https://i.imgur.com/zItfCEk.png" alt="" /></p>
<ul>
<li>new word like Starliner? can use <code>UNK</code> char</li>
</ul>
<p><img src="https://i.imgur.com/twmby69.png" alt="" /></p>
<ul>
<li>Break word down <code>##liner</code> from <code>starliner</code></li>
</ul>
<p><img src="https://i.imgur.com/OFg3afu.png" alt="" /></p>
<ul>
<li>Small vocab</li>
<li>No <code>UNK</code> tokens</li>
</ul>
<p><img src="https://i.imgur.com/Qz0dYAU.png" alt="" /></p>
<ul>
<li>Summarization, quadratic terms</li>
</ul>
<p><img src="https://i.imgur.com/oauz9sr.png" alt="" /></p>
<ul>
<li>He mixed up M and N. Don't need <code>N^2</code> term, small <code>M^2</code> term</li>
</ul>
<h2><a class="header" href="#bert-bidirectional-encoder-representations-from-transformers" id="bert-bidirectional-encoder-representations-from-transformers">Bert (Bidirectional Encoder Representations from Transformers)</a></h2>
<p><img src="https://i.imgur.com/Lkc4KuK.png" alt="" /></p>
<ul>
<li>Language model. Text is like a label, so it is like self labeling! Predict next word, previous word, etc.</li>
<li>Bert is a encoder model, bi-directional</li>
<li>GPT is a decoder model</li>
</ul>
<p><img src="https://i.imgur.com/oYIMVEN.png" alt="" /></p>
<ul>
<li>No encoder, no cross attention (?)</li>
</ul>
<p><img src="https://i.imgur.com/aNnUldP.png" alt="" /></p>
<ul>
<li>Minimize language modeling loss</li>
</ul>
<p><img src="https://i.imgur.com/0mgUX62.png" alt="" /></p>
<ul>
<li>Apply GPT to:
<ul>
<li>classification (what kind of speech)</li>
<li>Entailment (a implies b, contraction, independent)</li>
<li>Similarity has both orders</li>
<li>Multiple Choice, run it multiple times!</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/qVblTh7.png" alt="" /></p>
<ul>
<li>More data, larger models keep getting better on performance!</li>
</ul>
<h2><a class="header" href="#summary" id="summary">Summary</a></h2>
<p><img src="https://i.imgur.com/gyL8pqy.png" alt="" /></p>
<h1><a class="header" href="#nlp-applications" id="nlp-applications">NLP Applications</a></h1>
<h2><a class="header" href="#review-2" id="review-2">Review</a></h2>
<p><img src="https://i.imgur.com/5mGuBFY.png" alt="" /></p>
<ul>
<li>There is self-attention</li>
<li>Masked attention, for decoder, can only see in the past</li>
</ul>
<h2><a class="header" href="#generation-vs-understanding" id="generation-vs-understanding">Generation vs Understanding</a></h2>
<ul>
<li>NLG generate sequence as words</li>
<li>NLU build a representation to be used for a task</li>
<li>Summarization can be seen as both
<ul>
<li>Abstract Summarization</li>
<li>Extractive Summarization (3 most important, not generating text in this case!)</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/Rn21lmM.png" alt="" /></p>
<ul>
<li>Pretraining: Language Modeling and Masked Language Modeling</li>
</ul>
<h2><a class="header" href="#bert" id="bert">BERT</a></h2>
<p><img src="https://i.imgur.com/GEp1YXT.png" alt="" /></p>
<ul>
<li><strong>Bidirectional</strong></li>
</ul>
<p><img src="https://i.imgur.com/5h9Shz5.png" alt="" /></p>
<ul>
<li>Can't do Language Modeling, cause we already have the word! The model would cheat</li>
<li>Instead mask some words. Guess the word!</li>
<li><strong>Next sentence prediction</strong>
<ul>
<li>Give Two sentences, does sentence two make sense to follow sentence one?</li>
<li>Learns to represent beyond the sentence</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/BycdfAl.png" alt="" /></p>
<ul>
<li>Mask word and next sentence prediction</li>
</ul>
<h3><a class="header" href="#masked-vs-regular-language-modeling" id="masked-vs-regular-language-modeling">Masked vs. Regular Language Modeling</a></h3>
<p><img src="https://i.imgur.com/xuqlfIZ.png" alt="" /></p>
<ul>
<li>bi-directionality is important 50% to 65%. Having masks allows you to do bi-directionality</li>
</ul>
<h3><a class="header" href="#contextual-word-embedding" id="contextual-word-embedding">Contextual Word Embedding</a></h3>
<p><img src="https://i.imgur.com/IFYurkY.png" alt="" /></p>
<ul>
<li><code>Run</code> has many meanings!</li>
<li>Unlike word2vec, we use these contexts by going through stacked layers of self-attention and transformation</li>
</ul>
<h2><a class="header" href="#bert-task-specialization" id="bert-task-specialization">BERT Task Specialization</a></h2>
<p><img src="https://i.imgur.com/GmFkv06.png" alt="" /></p>
<ul>
<li>Segment Embeddings?
<ul>
<li>Dif Sentences</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/qMllq9L.png" alt="" /></p>
<ul>
<li>Sentence Pair Classification</li>
<li>Single Sentence like sentiment classification</li>
<li>You can fine tune, it actually seems to work!
<ul>
<li>The residual layers can redirect to the relevant layers</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/85yLA3T.png" alt="" /></p>
<ul>
<li>BERT did really well on GLUE.</li>
</ul>
<h2><a class="header" href="#tasks" id="tasks">Tasks</a></h2>
<p><img src="https://i.imgur.com/LhCeK3Q.png" alt="" /></p>
<ul>
<li>entailment, contracts, neutral
<ul>
<li>Kids play in the garden, vs no one goes to the garden</li>
<li>Can be ambiguous - &quot;Do kids like playing Soccer?&quot; </li>
</ul>
</li>
<li>MultiGenre NLI
<ul>
<li>From Flickr and other datasets!</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/X2E7WAs.png" alt="" /></p>
<ul>
<li>SQuAD, not part of GLUE but common question answering</li>
<li>Big bias because the dataset always had an answer</li>
</ul>
<p><img src="https://i.imgur.com/S9TaXaF.png" alt="" /></p>
<ul>
<li>SQuAD 2.0 (adversarial questions)</li>
</ul>
<h3><a class="header" href="#transfer-learning" id="transfer-learning">Transfer Learning</a></h3>
<p><img src="https://i.imgur.com/pJ2sBgD.png" alt="" /></p>
<ul>
<li>Transformer -&gt; Pretrain on General Text -&gt; In-domain text -&gt; Fine-tune classification</li>
</ul>
<h3><a class="header" href="#evaluating-language-models---perplexity" id="evaluating-language-models---perplexity">Evaluating Language Models - Perplexity</a></h3>
<p><img src="https://i.imgur.com/jtMBbLd.png" alt="" /></p>
<ul>
<li>Uncertainty - normalize by length</li>
</ul>
<p><img src="https://i.imgur.com/sqQiATF.png" alt="" /></p>
<ul>
<li>GPT-2 beat models <strong>without finetuning</strong>, low perplexity</li>
</ul>
<h3><a class="header" href="#gpt-2-generation" id="gpt-2-generation">GPT-2 Generation</a></h3>
<p><img src="https://i.imgur.com/Bq29qiH.png" alt="" /></p>
<h3><a class="header" href="#multiple-languages" id="multiple-languages">Multiple Languages</a></h3>
<p><img src="https://i.imgur.com/MIh8YiK.png" alt="" /></p>
<ul>
<li>FAIR XLM did it with 15 languages</li>
</ul>
<p><img src="https://i.imgur.com/9dgRDQh.png" alt="" /></p>
<ul>
<li>Translation Language Modeling
<ul>
<li>Has some English, some French, when masked can learn to use the other lang</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#conversational-qa" id="conversational-qa">Conversational Q&amp;A</a></h3>
<p><img src="https://i.imgur.com/MoUX4AG.png" alt="" /></p>
<ul>
<li>Incomplete information</li>
</ul>
<h1><a class="header" href="#generative-models" id="generative-models">Generative Models</a></h1>
<h2><a class="header" href="#review-3" id="review-3">Review</a></h2>
<p><img src="https://i.imgur.com/xRqRDYu.png" alt="" /></p>
<h2><a class="header" href="#generative-models-1" id="generative-models-1">Generative Models</a></h2>
<ul>
<li>Variational Auto-Encoder (VAE)</li>
<li>Auto-Regressive Models</li>
<li>Transformers</li>
<li>Generative Adversarial Networks (next time)</li>
</ul>
<h2><a class="header" href="#generative-models-2" id="generative-models-2">Generative Models</a></h2>
<p><img src="https://i.imgur.com/jsJTn7h.png" alt="" /></p>
<ul>
<li><strong>Classifier</strong> vs <strong>Generator</strong>
<ul>
<li>Deep Learning can't be efficient to create full joint probability</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#auto-encoder" id="auto-encoder">Auto-Encoder</a></h2>
<p><img src="https://i.imgur.com/0uw6wI7.png" alt="" /></p>
<ul>
<li><strong>Encoder:</strong> Data Compressor</li>
<li><strong>Code:</strong> low dimension representation with information bottleneck</li>
<li><strong>Decoder:</strong> generative</li>
</ul>
<p><img src="https://i.imgur.com/dInFxyq.png" alt="" /></p>
<ul>
<li>One option is to invert the function
<ul>
<li>z -&gt; x' is non-differentiable so it requires reinforcement learning</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#implicit-auto-encoders" id="implicit-auto-encoders">Implicit Auto-Encoders</a></h3>
<p><img src="https://i.imgur.com/tZgN5Iz.png" alt="" /></p>
<ul>
<li>From Latent code <code>z</code> to output <code>x</code>, same \( \theta \)
<ul>
<li>VAE: approximation Instead you get a distribution, not a single <code>x</code></li>
</ul>
</li>
</ul>
<h3><a class="header" href="#variational-auto-encoders" id="variational-auto-encoders">Variational Auto-Encoders</a></h3>
<p><img src="https://i.imgur.com/CByY1dP.png" alt="" /></p>
<ul>
<li>\( q_{\phi}(z|x) \): going up approximate inverse
<ul>
<li>\( p_{\theta}(z|x) \)</li>
</ul>
</li>
<li>What are these equations?
<ul>
<li>Theta vs phi</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/cl6xJLd.png" alt="" /></p>
<ul>
<li>Therefore there are two sets of parameters instead</li>
</ul>
<p><img src="https://i.imgur.com/N96QvIi.png" alt="" /></p>
<ul>
<li>\( \epsilon \) is noise
<ul>
<li>g can be a normal network</li>
<li>Both parts can be learn by backprop</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/FAKPt7t.png" alt="" /></p>
<ul>
<li>Max the probability of x given
<ul>
<li>marginal likelihood so we have un-marginalize it</li>
<li>written as an expectation (Expectation from \( E_{z~q_{\phi}(z|x^i)} \))</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/llP1nTk.png" alt="" /></p>
<ul>
<li>It's like the MLE trick</li>
</ul>
<p><img src="https://i.imgur.com/bQUYyf3.png" alt="" /></p>
<ul>
<li>Since it's concave, there's a <strong>tangent line</strong>
<ul>
<li>always less than or equal to that point</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/jdAxioF.png" alt="" /></p>
<p><img src="https://i.imgur.com/dMF1SMB.png" alt="" /></p>
<ul>
<li>?</li>
</ul>
<h2><a class="header" href="#optimizing-reparametrized-models" id="optimizing-reparametrized-models">Optimizing Reparametrized Models</a></h2>
<p><img src="https://i.imgur.com/MhtvPk9.png" alt="" /></p>
<ul>
<li></li>
</ul>
<p><img src="https://i.imgur.com/3q6PAJ5.png" alt="" /></p>
<ul>
<li>LMAO I'm confused plz help</li>
<li>Expected value: Integral</li>
<li>repraram the network with epsilon noise</li>
<li>the final equation is like SGD?
<ul>
<li>I think they meant it's like sampling </li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/VdhyTvM.png" alt="" /></p>
<ul>
<li>We can approximate things</li>
</ul>
<p><img src="https://i.imgur.com/I9m3zRo.png" alt="" /></p>
<ul>
<li>Let's be honest this is black magic at this point.
<ul>
<li>High variance from samples?</li>
<li>sample from equiv distributions instead</li>
<li>Wait this actually makes sense</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/d1vWYxe.png" alt="" /></p>
<p><img src="https://i.imgur.com/HsV8Cey.png" alt="" /></p>
<ul>
<li>Can kind of generate faces</li>
</ul>
<h2><a class="header" href="#autoregressive-models" id="autoregressive-models">Autoregressive Models</a></h2>
<p><img src="https://i.imgur.com/GuEsiT8.png" alt="" /></p>
<ul>
<li>Pixels are correlated</li>
<li>\( p(x_i | x_{i-1}, x_{i-2}, ...) \) conditioned on previous inputs</li>
</ul>
<p><img src="https://i.imgur.com/vtmFje2.png" alt="" /></p>
<p><img src="https://i.imgur.com/1MrQGev.png" alt="" /></p>
<ul>
<li>CNN is an empty image</li>
</ul>
<p><img src="https://i.imgur.com/tYVH9Ia.png" alt="" /></p>
<ul>
<li>and feed it back in</li>
</ul>
<p><img src="https://i.imgur.com/jg7dJ2K.png" alt="" /></p>
<ul>
<li>slow generation, fast training! it can be done in parallel!</li>
</ul>
<p><img src="https://i.imgur.com/E0U6ytC.png" alt="" /></p>
<ul>
<li>Use LSTM from row above, therefore can generate row in parallel!</li>
</ul>
<p><img src="https://i.imgur.com/E0U6ytC.png" alt="" /></p>
<ul>
<li>bam!</li>
</ul>
<p><img src="https://i.imgur.com/adhQ1Xj.png" alt="" /></p>
<ul>
<li>You can use previous rows, or all seen before!</li>
</ul>
<h3><a class="header" href="#examples" id="examples">Examples</a></h3>
<p><img src="https://i.imgur.com/6TbDfEO.jpg" alt="" /></p>
<ul>
<li>Good but with distortions</li>
</ul>
<p><img src="https://i.imgur.com/RbhuYF5.jpg" alt="" /></p>
<ul>
<li>Ok</li>
</ul>
<h2><a class="header" href="#image-transformer" id="image-transformer">Image Transformer</a></h2>
<p><img src="https://i.imgur.com/WJOARPJ.png" alt="" /></p>
<ul>
<li>Like generating text
<ul>
<li>multi-head attention</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/f5LrKTS.png" alt="" /></p>
<ul>
<li>2D Memory Block, left is a transformer</li>
</ul>
<h1><a class="header" href="#generative-adversarial-networks" id="generative-adversarial-networks">Generative Adversarial Networks</a></h1>
<h2><a class="header" href="#last-time" id="last-time">Last Time</a></h2>
<p><img src="https://i.imgur.com/LCa14jA.png" alt="" /></p>
<ul>
<li>network \( p_{\theta} \)</li>
</ul>
<p><img src="https://i.imgur.com/ADhTUfX.png" alt="" /></p>
<ul>
<li>PixelCNN</li>
</ul>
<p><img src="https://i.imgur.com/jD6YkiT.png" alt="" /></p>
<ul>
<li>Autoregressive conditioned on the input</li>
<li>Posterior distribution</li>
<li>Model human discriminating</li>
</ul>
<h2><a class="header" href="#problems-of-variational-auto-encoders" id="problems-of-variational-auto-encoders">Problems of Variational Auto-Encoders</a></h2>
<p><img src="https://i.imgur.com/0ZfYPLQ.png" alt="" /></p>
<ul>
<li>Compares densities in <strong>latent z space</strong></li>
</ul>
<p><img src="https://i.imgur.com/hSX7tTl.png" alt="" /></p>
<p><img src="https://i.imgur.com/srG2XiI.png" alt="" /></p>
<ul>
<li>Avoid approximations and density estimates</li>
</ul>
<p><img src="https://i.imgur.com/srG2XiI.png" alt="" /></p>
<ul>
<li>Real and Synthetic Image distribution \( p_{re}(x) \)</li>
<li>Has KL divergence and approximate expected values by sampling</li>
</ul>
<p><img src="https://i.imgur.com/VoRvTK5.png" alt="" /></p>
<ul>
<li>Wait what?</li>
<li>\( d_{\phi} \) is softmax - so it is a classifier</li>
</ul>
<p><img src="https://i.imgur.com/q3iiMMI.png" alt="" /></p>
<ul>
<li>First equation is plus
<ul>
<li>We are minimizing the divergence</li>
</ul>
</li>
<li>Second equation is minus.
<ul>
<li>We are optimizing the discriminator</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/miQHrAw.png" alt="" /></p>
<ul>
<li>Proof of classifier</li>
</ul>
<p><img src="https://i.imgur.com/G0tU2ga.png" alt="" /></p>
<ul>
<li>Written as one formula</li>
<li>Now we add a generator \( g_{\theta} \) being maximized</li>
</ul>
<p><img src="https://i.imgur.com/rwJe94j.png" alt="" /></p>
<ul>
<li>Two player game</li>
</ul>
<p><img src="https://i.imgur.com/DOJaVTh.png" alt="" /></p>
<ul>
<li>Generate from Latent space to image</li>
</ul>
<p><img src="https://i.imgur.com/SOxLluY.png" alt="" /></p>
<ul>
<li>Classifies realness. </li>
<li>Maximizes (or minimize) divergence? what does that mean</li>
</ul>
<p><img src="https://i.imgur.com/zMuCciB.png" alt="" /></p>
<ul>
<li>Can backprop all the way! End-to-end</li>
</ul>
<p><img src="https://i.imgur.com/GTWN3FI.png" alt="" /></p>
<ul>
<li></li>
</ul>
<p><img src="https://i.imgur.com/Nn5x37g.png" alt="" /></p>
<ul>
<li>Step 1 update discriminator</li>
<li>Step 2 update generator</li>
</ul>
<p><img src="https://i.imgur.com/8x6Zh9J.png" alt="" /></p>
<ul>
<li>Big gradients when outputs are bad.</li>
</ul>
<p><img src="https://i.imgur.com/jcBeurj.png" alt="" /></p>
<ul>
<li>Does pretty well! (2014)</li>
</ul>
<h2><a class="header" href="#gan-improvements" id="gan-improvements">GAN Improvements</a></h2>
<p><a href="https://github.com/soumith/ganhacks">GAN Hacks</a></p>
<p><img src="https://i.imgur.com/TvpPXWB.png" alt="" /></p>
<ul>
<li>Progressively going up in</li>
<li>Fractional Stride Convolution</li>
</ul>
<p><img src="https://i.imgur.com/yivjQGN.png" alt="" /></p>
<ul>
<li>Can do arithmetic on this! Man with glasses! without!</li>
</ul>
<p><img src="https://i.imgur.com/ME1p60T.png" alt="" /></p>
<ul>
<li>Add a class label</li>
</ul>
<p><img src="https://i.imgur.com/ME1p60T.png" alt="" /></p>
<ul>
<li>Text to Image synthesis to both generator and discriminator
<ul>
<li><code>This flower has small round violet petals with a dark purple center.</code></li>
</ul>
</li>
</ul>
<h2><a class="header" href="#gan-problems" id="gan-problems">GAN Problems</a></h2>
<p><img src="https://i.imgur.com/2OnYLJR.png" alt="" /></p>
<ul>
<li>only learns to generate South Pole</li>
<li>But then starts to generate Alice Springs</li>
<li>Unstable</li>
</ul>
<p><img src="https://i.imgur.com/aXGncYz.png" alt="" /></p>
<ul>
<li>Experience replay - old discriminator and generator.</li>
</ul>
<p><img src="https://i.imgur.com/0m2YB88.png" alt="" /></p>
<ul>
<li>Wasserstein Distance</li>
</ul>
<p><img src="https://i.imgur.com/UIgAppt.png" alt="" /></p>
<ul>
<li>Critic function diffs approximate the Wasserstein GAN</li>
</ul>
<p><img src="https://i.imgur.com/s780qW2.png" alt="" /></p>
<ul>
<li>Provably avoids mode collapse - train to optimality</li>
</ul>
<p><img src="https://i.imgur.com/yyXoOeQ.png" alt="" /></p>
<p><img src="https://i.imgur.com/a55wcBI.png" alt="" /></p>
<ul>
<li>Scale up, don't need progressive GAN</li>
</ul>
<p><img src="https://i.imgur.com/IvEgb8x.png" alt="" /></p>
<ul>
<li>Upsampling - generator</li>
</ul>
<h2><a class="header" href="#evaluating-gans" id="evaluating-gans">Evaluating GANs</a></h2>
<p><img src="https://i.imgur.com/oawobnd.png" alt="" /></p>
<ul>
<li>Inception Score</li>
<li>Using Inception v3 Network</li>
<li>Multi-resolution convolutions
<ul>
<li>1x1, 3x3, 5x5 blocks</li>
<li>like humans</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/OL9fRyo.png" alt="" /></p>
<ul>
<li>Another improvement on evaluation</li>
</ul>
<h2><a class="header" href="#unpaired-conditional-image-generation" id="unpaired-conditional-image-generation">Unpaired Conditional Image Generation</a></h2>
<p><img src="https://i.imgur.com/ZfgRSf0.png" alt="" /></p>
<ul>
<li>not paired. Use a corresponding image and generate a synthetic image</li>
</ul>
<p><img src="https://i.imgur.com/ZWXiMn2.png" alt="" /></p>
<ul>
<li><strong>CycleGAN</strong> create a cycle 2 generators and 2 discriminators
<ul>
<li>cycle-consistency loss L1 distance</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/ZWXiMn2.png" alt="" /></p>
<ul>
<li>Really remarkable</li>
<li>Compared to neural style
<ul>
<li>Neural style uses statistics</li>
<li>Harder to discriminate</li>
</ul>
</li>
</ul>
<h1><a class="header" href="#adversarial-networks" id="adversarial-networks">Adversarial Networks</a></h1>
<h2><a class="header" href="#last-time-1" id="last-time-1">Last Time</a></h2>
<p><img src="https://i.imgur.com/ZfCDGqe.png" alt="" /></p>
<h2><a class="header" href="#security-and-adversarial-environments" id="security-and-adversarial-environments">Security and Adversarial Environments</a></h2>
<p><img src="https://i.imgur.com/cIWLWv7.png" alt="" /></p>
<ul>
<li>The Training Data is like the Testing Data</li>
</ul>
<p><img src="https://i.imgur.com/hNgGsgd.png" alt="" /></p>
<ul>
<li>Using a little adversarial noise
<ul>
<li>Fast Gradient Sign</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/gfaUjoM.png" alt="" /></p>
<ul>
<li>Optimization, minimize divergence (prebutation) but change the classification</li>
<li>Easy if you have the network!</li>
</ul>
<h2><a class="header" href="#autonomous-driving" id="autonomous-driving">Autonomous Driving</a></h2>
<p><img src="https://i.imgur.com/1njidkF.png" alt="" /></p>
<ul>
<li>Changes</li>
</ul>
<p><img src="https://i.imgur.com/NWptCXD.png" alt="" /></p>
<ul>
<li>Use a mask and now can disguise it?</li>
</ul>
<p><img src="https://i.imgur.com/UwXlpsM.png" alt="" /></p>
<ul>
<li>To print, the color has to be printable. Sample from the color space</li>
</ul>
<p><img src="https://i.imgur.com/HYAmxI5.png" alt="" /></p>
<ul>
<li>Fast use only sign of gradients</li>
</ul>
<p><img src="https://i.imgur.com/HYAmxI5.png" alt="" /></p>
<ul>
<li>Zero-Query Attack
<ul>
<li>Can't try it out</li>
</ul>
</li>
<li>Query Based Attack
<ul>
<li>Make queries and estimate the attack</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/lcBMo5v.png" alt="" /></p>
<ul>
<li>Try to attack but Ensembles are an effective defense</li>
</ul>
<p><img src="https://i.imgur.com/KIgfzGq.png" alt="" /></p>
<ul>
<li>Low Transferability</li>
</ul>
<p><img src="https://i.imgur.com/CBEB75u.png" alt="" /></p>
<ul>
<li>Try many models and try to make a single adversarial example to be effective against all models</li>
</ul>
<p><img src="https://i.imgur.com/KVJkInX.png" alt="" /></p>
<ul>
<li>Use a positive and negative, find the finite difference</li>
<li>Finite Difference is really good,
PCA is really good</li>
<li>want low number of queries</li>
</ul>
<p>Another option is to use GANs.</p>
<p><img src="https://i.imgur.com/Xg6oYqA.png" alt="" /></p>
<ul>
<li>Averaging, Ensembling,</li>
</ul>
<h2><a class="header" href="#attacking-generative-models" id="attacking-generative-models">Attacking Generative Models</a></h2>
<p><img src="https://i.imgur.com/vsCcfqL.png" alt="" /></p>
<p><img src="https://i.imgur.com/FAJruaw.png" alt="" /></p>
<p><img src="https://i.imgur.com/7FNrzQJ.png" alt="" /></p>
<ul>
<li>VAE-GAN to all 0s!</li>
</ul>
<p><img src="https://i.imgur.com/cjAPqfF.png" alt="" /></p>
<h2><a class="header" href="#visual-question--answering" id="visual-question--answering">Visual Question &amp; Answering</a></h2>
<p><img src="https://i.imgur.com/z76RhLz.png" alt="" /></p>
<h2><a class="header" href="#attack-reinforcement-networks" id="attack-reinforcement-networks">Attack Reinforcement Networks</a></h2>
<p><img src="https://i.imgur.com/XO96Mu9.png" alt="" /></p>
<p><img src="https://i.imgur.com/78Bcd2T.png" alt="" /></p>
<ul>
<li></li>
</ul>
<h1><a class="header" href="#fairness-in-deep-learning" id="fairness-in-deep-learning">Fairness in Deep Learning</a></h1>
<p>Deep Learning has bias</p>
<p><img src="https://i.imgur.com/HeZAFL6.png" alt="" /></p>
<ul>
<li>Universal Approximation, but
<ul>
<li>the data we train can have <strong>sampling bias</strong>
<ul>
<li>Australians are under-represented</li>
</ul>
</li>
<li><strong>selection bias</strong></li>
</ul>
</li>
<li>But actually want bias to be equal to variance</li>
</ul>
<h2><a class="header" href="#unawareness-in-fairness" id="unawareness-in-fairness">Unawareness in Fairness</a></h2>
<p><img src="https://i.imgur.com/eNJiAGY.png" alt="" /></p>
<ul>
<li>\( A \) is protected attribute</li>
<li>we want <strong>unawareness</strong>, \( f(X, A)=f(X) \)</li>
</ul>
<h2><a class="header" href="#demographyc-parity" id="demographyc-parity">Demographyc Parity</a></h2>
<p><img src="https://i.imgur.com/vK5rwFn.png" alt="" /></p>
<ul>
<li>\( P(\hat{Y}=1|A=Australian) = P(\hat{Y}=1|A=American)\)</li>
<li>The prediction is independent?</li>
<li>There is a notation</li>
</ul>
<p><img src="https://i.imgur.com/sZE9srs.png" alt="" /></p>
<ul>
<li>somehow unfair</li>
</ul>
<h2><a class="header" href="#all-other-things-being-equal" id="all-other-things-being-equal">All Other Things Being Equal</a></h2>
<p><img src="https://i.imgur.com/ALTQ9ZI.png" alt="" /></p>
<ul>
<li>Think about hypothetical outputs</li>
<li><code>Causal Inference</code></li>
</ul>
<h2><a class="header" href="#separation" id="separation">Separation</a></h2>
<p><img src="https://i.imgur.com/3EggPu1.png" alt="" /></p>
<ul>
<li>Separation is Conditionally Independent given \( Y \)</li>
</ul>
<p><img src="https://i.imgur.com/LyiAGIk.png" alt="" /></p>
<ul>
<li>Constrain it more such that \( Y=1 \)
<ul>
<li>Only be fair for people worthy of loans</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#sufficiency" id="sufficiency">Sufficiency</a></h2>
<ul>
<li>Too complicated</li>
</ul>
<h2><a class="header" href="#causal-reasoning" id="causal-reasoning">Causal Reasoning</a></h2>
<p><img src="https://i.imgur.com/Puzi4he.png" alt="" /></p>
<ul>
<li>Graphical Models, for factorization of joint distribution</li>
</ul>
<p><img src="https://i.imgur.com/3nDF36r.png" alt="" /></p>
<ul>
<li>as an algorithm
<ul>
<li>sampling then joint distribution</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/1tQytMq.png" alt="" /></p>
<ul>
<li><code>intervention</code></li>
</ul>
<p><img src="https://i.imgur.com/1tQytMq.png" alt="" /></p>
<ul>
<li>in a graphical model there is a lot of other indirect effects</li>
</ul>
<h2><a class="header" href="#gan-like-optimization" id="gan-like-optimization">GAN like optimization</a></h2>
<p><img src="https://i.imgur.com/8oXEGK6.png" alt="" /></p>
<ul>
<li>with a Jenson Shannon Divergence
<ul>
<li>optimize distribution similarity</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/74zJRxd.png" alt="" /></p>
<ul>
<li>Y, and X</li>
<li>bottom is for fairness, protected value
<ul>
<li>switch between real vs fake</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/0T9b1gH.png" alt="" /></p>
<ul>
<li>lower bound</li>
</ul>
<p><img src="https://i.imgur.com/4uKD2aZ.png" alt="" /></p>
<ul>
<li>Conditional Mutual Information</li>
</ul>
<h2><a class="header" href="#summary-1" id="summary-1">Summary</a></h2>
<p><img src="https://i.imgur.com/x5JfLNm.png" alt="" /></p>
<ul>
<li></li>
</ul>
<h1><a class="header" href="#imitation-learning" id="imitation-learning">Imitation Learning</a></h1>
<ul>
<li>
<p>Fairness</p>
<ul>
<li>Unawareness</li>
<li>Domographic Parity</li>
<li>Separation</li>
<li>Sufficiency</li>
</ul>
</li>
<li>
<p>Causality</p>
<ul>
<li>it's hard to figure out hte dependency</li>
<li>disease such as for pregnancy does have bias to gender</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#imitation-learning-1" id="imitation-learning-1">Imitation Learning</a></h2>
<ul>
<li>Robot</li>
<li>Imitate Human actions
<ul>
<li><strong>behavior cloning</strong> also known as <strong>sensorimotor learning</strong></li>
<li>end-to-end vision</li>
</ul>
</li>
<li>Markov Decision Process
<ul>
<li>\( s_t \) - state</li>
<li>\( a_t \) - action</li>
<li>\( r_t \) - reward
<ul>
<li>deterministic</li>
</ul>
</li>
<li>\( \pi_\theta (a_t | s_t) \) - policy: probability</li>
</ul>
</li>
<li>For Partially Observable
<ul>
<li>\( \pi_\theta (a_t | o_t) \) - policy: probability of action \( a_t \) given obseration \( o_t \)</li>
<li>\( o_t \)</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/jDI1ZiI.png" alt="" /></p>
<ul>
<li>errors accumulate</li>
</ul>
<p><img src="https://i.imgur.com/x6hT1n3.png" alt="" /></p>
<p><img src="https://i.imgur.com/lhpVC4R.png" alt="" /></p>
<ul>
<li>left, center, and right camera</li>
</ul>
<p><img src="https://i.imgur.com/Fs8e7Yv.png" alt="" /></p>
<ul>
<li>the right camera gives the signal turn left</li>
</ul>
<p><img src="https://i.imgur.com/NM18VPb.png" alt="" /></p>
<ul>
<li>behavior policy what the agent uses</li>
<li>target policy - ?</li>
</ul>
<p><img src="https://i.imgur.com/HOapigK.png" alt="" /></p>
<ul>
<li>states from policy</li>
<li>but labels from human</li>
</ul>
<p><img src="https://i.imgur.com/wpRSTbW.png" alt="" /></p>
<ul>
<li>but have to get policies from a human</li>
</ul>
<h2><a class="header" href="#gail-generative-adversarial-imitation-learning" id="gail-generative-adversarial-imitation-learning">GAIL: Generative Adversarial Imitation Learning</a></h2>
<p><img src="https://i.imgur.com/dfseUk0.png" alt="" /></p>
<ul>
<li><strong>Inverse Reinforcement Learning (IRL)</strong>
<ul>
<li>estimate cost function (loss function or -reward function)</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/61l56O0.png" alt="" /></p>
<ul>
<li>under constrained - use regularization heuristics
<ul>
<li>minimize entropy regularization</li>
<li>learn the cost function</li>
<li>that we know the cost function the RL policy learning problem uses the new cost function</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/uf7Ww4C.png" alt="" /></p>
<ul>
<li>low level behavioral policy</li>
</ul>
<p><img src="https://i.imgur.com/uf7Ww4C.png" alt="" /></p>
<ul>
<li><strong>on-policy</strong></li>
<li>GAIL, more powerful find the cost function then use RL</li>
</ul>
<h1><a class="header" href="#reinforcement-learning-policy-gradients" id="reinforcement-learning-policy-gradients">Reinforcement Learning: Policy Gradients</a></h1>
<p><a href="https://www.youtube.com/watch?v=rpKkZ71A_xE">Link</a></p>
<p><img src="https://i.imgur.com/1JuznSr.png" alt="" /></p>
<ul>
<li>You have a:
<ul>
<li><strong>state</strong></li>
<li>which you observe with an <strong>observation</strong></li>
<li>you choose what action to take (<strong>policy</strong>)
<ul>
<li>\( \pi_{\theta} ( a_t | o_t ) \)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/2NCCfsM.png" alt="" /></p>
<ul>
<li>we use a reward function
<ul>
<li>what is the best action for this state?</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#markov-decision" id="markov-decision">Markov Decision</a></h2>
<p><img src="https://i.imgur.com/txTpesj.png" alt="" /></p>
<ul>
<li>Markov Chain</li>
<li>transition is indepedent of state before previous state</li>
</ul>
<p><img src="https://i.imgur.com/dTVyPYO.png" alt="" /></p>
<ul>
<li>Transition is a tensor with state and action</li>
</ul>
<p><img src="https://i.imgur.com/txTpesj.png" alt="" /></p>
<ul>
<li>reward function takes a state and action </li>
<li>trajectory is a sequence of states and actions</li>
</ul>
<p><img src="https://i.imgur.com/HEHm68j.png" alt="" /></p>
<ul>
<li>states are orange</li>
<li>actions are green, transition probabilities are green</li>
<li>rewards are red
<ul>
<li>some are zero some are non-zero</li>
</ul>
</li>
<li>environment can transition to another state</li>
<li>at \( s_0 \) you could take \( a_0 \) with prob 0.3 or other 0.7. Taking \( a_0 \) has prob 0.2 to go to \( s_1 \) or 0.8 to \( s_1' \)</li>
</ul>
<h2><a class="header" href="#reinforcement-learning" id="reinforcement-learning">Reinforcement Learning</a></h2>
<p><img src="https://i.imgur.com/4pOOxOm.png" alt="" /></p>
<ul>
<li>the model learns the policy!
<ul>
<li>\( \pi_theta(a | s) \)</li>
</ul>
</li>
<li>the probability is the state and action is </li>
<li>the goal is to find the parameters that maximizes expected reward
<ul>
<li>all rewards from transitions taken</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#value-functions" id="value-functions">Value Functions</a></h2>
<p><img src="https://i.imgur.com/J9rVYCc.png" alt="" /></p>
<ul>
<li>value of a state
<ul>
<li>sum for each action</li>
<li>policy (which is a probability) (think like after softmax before argmax)</li>
<li>times reward</li>
<li>plus sum of total future rewards
<ul>
<li>Value future reward</li>
<li>probability to enter that state</li>
</ul>
</li>
</ul>
</li>
<li>it's recursive</li>
</ul>
<h2><a class="header" href="#belmman-updadte" id="belmman-updadte">Belmman Updadte</a></h2>
<p><img src="https://i.imgur.com/jwTBMMz.png" alt="" /></p>
<ul>
<li>Take the action that maximizes the term (reward + future scaled &quot;expected&quot; value from reward)</li>
</ul>
<p><img src="https://i.imgur.com/KYVHn4L.png" alt="" /></p>
<ul>
<li>to get values, initialize each state value to zero, and update
<ul>
<li>state 1.0 get reward 1, etc.</li>
</ul>
</li>
<li>Then propogates the weights back 2.2 -&gt; 2.0 because of 2.2 * .9 = 1.98 -&gt; 2.0</li>
</ul>
<p><img src="https://i.imgur.com/PPtIYRq.png" alt="" /></p>
<ul>
<li>But there can be cycles!
<ul>
<li><strong>not dynamic programming</strong></li>
</ul>
</li>
<li>if acyclic, then is O(SA) # states, # actions</li>
</ul>
<p><img src="https://i.imgur.com/VcuDz1x.png" alt="" /></p>
<ul>
<li>infinite horozon vs finite horizon?</li>
</ul>
<h2><a class="header" href="#challenges-of-reinforcement-learning" id="challenges-of-reinforcement-learning">Challenges of Reinforcement Learning</a></h2>
<p><img src="https://i.imgur.com/pLKiHis.png" alt="" /></p>
<ul>
<li>the reward takes action which is discrete. We can't differentiate through this.</li>
<li>Don't know the reward function</li>
<li><code>Temporal Credit Assignment Problem</code>
<ul>
<li>hundreds of actions to get to this step, they don't have any reward</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#policy-gradient-approaches" id="policy-gradient-approaches">Policy Gradient Approaches</a></h2>
<p><img src="https://i.imgur.com/XCbcH5n.png" alt="" /></p>
<ul>
<li>we can estimate the gradient</li>
</ul>
<p><img src="https://i.imgur.com/5mjNigf.png" alt="" /></p>
<ul>
<li>we want \( J(\theta) \)
<ul>
<li>we can approximate it with samples \(  \frac{1}{N} \sum_{i} ...\)</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/H6DmBUp.png" alt="" /></p>
<ul>
<li>\( J(\theta) = \int \pi_{\theta} (\tau) r(\tau) d\tau \)
<ul>
<li>our policy network and the reward it would get</li>
</ul>
</li>
<li>to update our weights in the policy network
<ul>
<li>we can sample gradient log of our policy and the rewards it gets</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/JqZXAGu.png" alt="" /></p>
<ul>
<li>our policy - based on all states and actions up to the current state and action
<ul>
<li>it is the probability of the initial state, and probability to get to our state</li>
</ul>
</li>
<li>expanded, they have no theta, so are zero.</li>
<li><code>solution</code> sample from </li>
</ul>
<p><img src="https://i.imgur.com/8NZVd9n.png" alt="" /></p>
<ul>
<li>run the policy</li>
<li>get gradient which is possible on each action individually</li>
</ul>
<p><img src="https://i.imgur.com/cVo1C6S.png" alt="" /></p>
<ul>
<li>minimizes gradient of crostt-entropy loss
<ul>
<li>as a neural network - forward state -&gt; policy -&gt; action</li>
<li>gradient correct action -&gt; policy network</li>
</ul>
</li>
<li>ml problem of classification \( s_t, a_t \)</li>
</ul>
<p><img src="https://i.imgur.com/MbGYoCC.png" alt="" /></p>
<ul>
<li>predicting a continuous value - find mean</li>
</ul>
<h2><a class="header" href="#reducing-variance" id="reducing-variance">Reducing Variance</a></h2>
<p><img src="https://i.imgur.com/ICOSb7W.png" alt="" /></p>
<ul>
<li>reward to go, Q function?</li>
</ul>
<p><img src="https://i.imgur.com/eXsugYo.png" alt="" /></p>
<ul>
<li>subtract the baseline (average)
<ul>
<li>it's unbiased</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#off-policy-learning" id="off-policy-learning">Off Policy Learning</a></h2>
<ul>
<li>like from a human (not from the network's policy)</li>
</ul>
<p><img src="https://i.imgur.com/RprgdRc.png" alt="" /></p>
<ul>
<li>from another distribution \( q(x) \)</li>
<li>need a correction factor of L where expectation is 1</li>
<li>just use them as a ratio</li>
</ul>
<p><img src="https://i.imgur.com/U4dNmCa.png" alt="" /></p>
<ul>
<li>update using current policy but sampling from \( \pi_{\theta'} \)</li>
</ul>
<h2><a class="header" href="#challenges-with-policy-gradients" id="challenges-with-policy-gradients">Challenges with Policy Gradients</a></h2>
<p><img src="https://i.imgur.com/F1pgAaQ.png" alt="" /></p>
<ul>
<li>O(NT) - lots of steps</li>
<li>Gradient estimate has hith variance</li>
</ul>
<p><img src="https://i.imgur.com/sHUPFjL.png" alt="" /></p>
<ul>
<li>gradients steps expensive, minimize number of steps</li>
</ul>
<p><img src="https://i.imgur.com/h65y6vY.png" alt="" /></p>
<ul>
<li>use new reward - maximize with penalty large change in \( \pi_{\theta} \) ?</li>
</ul>
<h2><a class="header" href="#trust-region-policy-optimization" id="trust-region-policy-optimization">Trust Region Policy Optimization</a></h2>
<p><img src="https://i.imgur.com/IWJATL1.png" alt="" /></p>
<ul>
<li>make sure the sample from reward in \( \pi_{\theta'} \) similar to \( \pi_{\theta} \)</li>
</ul>
<p><img src="https://i.imgur.com/AF8S8C2.png" alt="" /></p>
<ul>
<li>uses a natural gradient like a newton step</li>
</ul>
<h2><a class="header" href="#proximal-policy-optimization" id="proximal-policy-optimization">Proximal Policy Optimization</a></h2>
<p><img src="https://i.imgur.com/qXC1aK6.png" alt="" /></p>
<ul>
<li>instead of KL divergence</li>
<li>resists changes?</li>
</ul>
<h1><a class="header" href="#deep-rl-value-based-method" id="deep-rl-value-based-method">Deep RL: Value-Based Method</a></h1>
<p><img src="https://i.imgur.com/P8oAd1Y.png" alt="" /></p>
<ul>
<li>theta is weights, goal is to optimize total sum reward</li>
</ul>
<p><img src="https://i.imgur.com/FKp4duA.png" alt="" /></p>
<ul>
<li>get policy gradients. Take multiple samples and calculate the gradient</li>
<li>but it is expensive has to take many steps</li>
<li>TRPO and PPO (look at amount of change)</li>
</ul>
<h2><a class="header" href="#value-function" id="value-function">Value Function</a></h2>
<p><img src="https://i.imgur.com/g4R3YEZ.png" alt="" /></p>
<ul>
<li>value is the discounted reward-to-go</li>
<li>value is the probability of taking that action, actual reward, and discount of future total reward</li>
</ul>
<p><img src="https://i.imgur.com/S0dE5JJ.png" alt="" /></p>
<ul>
<li>\( Q^{\pi}(s, a) \) expectation on both state and action</li>
<li>the value function is the expectation oe all future discounted rewards
<ul>
<li>expectation of a sampled from Q, for all </li>
</ul>
</li>
<li>advantage function, reduces magnitude, lower variance</li>
</ul>
<h2><a class="header" href="#trpo-and-ppo-use-advantage" id="trpo-and-ppo-use-advantage">TRPO and PPO use Advantage</a></h2>
<p><img src="https://i.imgur.com/bhqJUpo.png" alt="" /></p>
<ul>
<li>\( A^{\theta} \) at the end</li>
</ul>
<h2><a class="header" href="#actor-critic-introduction" id="actor-critic-introduction">Actor-Critic Introduction</a></h2>
<p><img src="https://i.imgur.com/ivQDaNY.png" alt="" /></p>
<ul>
<li>actor: policy</li>
<li>critic: value estimator</li>
</ul>
<p><img src="https://i.imgur.com/dPMqdEi.png" alt="" /></p>
<ul>
<li>compute value func and advantage func (Q func implicitly)</li>
<li>sample by running on our robot</li>
<li>online:
<ul>
<li>sample action from policy</li>
<li>update V with target?</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/EmcInDw.png" alt="" /></p>
<ul>
<li>you can just take the best action</li>
</ul>
<p><img src="https://i.imgur.com/2lOOQ64.png" alt="" /></p>
<ul>
<li>finding best in action function, you can actually just use the Q-func</li>
</ul>
<h2><a class="header" href="#fitted-q-iteration" id="fitted-q-iteration">Fitted Q-iteration</a></h2>
<p><img src="https://i.imgur.com/3qwZu42.png" alt="" /></p>
<ul>
<li>what is \(y_i\)  (temp)</li>
<li>find \( \rho \)</li>
</ul>
<h2><a class="header" href="#off-policy-vs-on-policy-state-visitation" id="off-policy-vs-on-policy-state-visitation">Off-Policy vs On-Policy State Visitation</a></h2>
<p><img src="https://i.imgur.com/JYPagBL.png" alt="" /></p>
<ul>
<li>can easily diverge</li>
</ul>
<p><img src="https://i.imgur.com/afiMaba.png" alt="" /></p>
<ul>
<li>iteratively fit, using final game state (final reward)</li>
</ul>
<h2><a class="header" href="#online-q-learning" id="online-q-learning">Online Q-learning</a></h2>
<p><img src="https://i.imgur.com/kwCf1PT.png" alt="" /></p>
<p><img src="https://i.imgur.com/FrBqFlE.png" alt="" /></p>
<ul>
<li>it's deterministic prob are 0 or 1.</li>
<li>use epsilon greedy - now probabilitic and learns</li>
</ul>
<h2><a class="header" href="#correlation-problem" id="correlation-problem">Correlation Problem</a></h2>
<p><img src="https://i.imgur.com/jvC02fP.png" alt="" /></p>
<ul>
<li>states are correlated </li>
</ul>
<h2><a class="header" href="#another-solution-replay-buffers" id="another-solution-replay-buffers">Another Solution: Replay Buffers</a></h2>
<p><img src="https://i.imgur.com/2KOMZ9k.png" alt="" /></p>
<ul>
<li>save tuples from dataset. They are less likely correlated</li>
</ul>
<p><img src="https://i.imgur.com/4We9ue8.png" alt="" /></p>
<h2><a class="header" href="#q-learning-with-target-networks" id="q-learning-with-target-networks">Q-Learning with Target Networks</a></h2>
<p><img src="https://i.imgur.com/dOC1zZY.png" alt="" /></p>
<h2><a class="header" href="#classic-dqn-in-homework" id="classic-dqn-in-homework">Classic DQN (In Homework)</a></h2>
<p><img src="https://i.imgur.com/MkxJgy7.png" alt="" /></p>
<ul>
<li>theta for network weights, rho is the input, 84x84 4 frames</li>
</ul>
<p><img src="https://i.imgur.com/FD7So4H.png" alt="" /></p>
<ul>
<li><strong>frame history state</strong></li>
</ul>
<p><img src="https://i.imgur.com/FD7So4H.png" alt="" /></p>
<ul>
<li>convolution layer</li>
</ul>
<p><img src="https://i.imgur.com/MzS5Jqj.png" alt="" /></p>
<ul>
<li>usually an overestimate</li>
</ul>
<p><img src="https://i.imgur.com/qw2YSst.png" alt="" /></p>
<h2><a class="header" href="#double-q-learning" id="double-q-learning">Double Q-Learning</a></h2>
<p><img src="https://i.imgur.com/MaYvz9R.png" alt="" /></p>
<ul>
<li>instead of a (action) use the best action from another policy! It's unbiased!</li>
</ul>
<p><img src="https://i.imgur.com/wmjR4uh.png" alt="" /></p>
<ul>
<li>use the <strong>current network</strong></li>
<li>and <strong>target network</strong> which is just delayed</li>
</ul>
<p><img src="https://i.imgur.com/Exs67av.png" alt="" /></p>
<p><img src="https://i.imgur.com/mKQNR2s.png" alt="" /></p>
<ul>
<li>? </li>
</ul>
<p><img src="https://i.imgur.com/Gdxnq3A.png" alt="" /></p>
<ul>
<li>rainbow</li>
</ul>
<h2><a class="header" href="#professor-john-canny-on-a-beach" id="professor-john-canny-on-a-beach">Professor John Canny on a Beach</a></h2>
<p><img src="https://i.imgur.com/MYLYwR7.png" alt="" /></p>
<h1><a class="header" href="#exploration" id="exploration">Exploration</a></h1>
<p><img src="https://i.imgur.com/gVCuOe3.png" alt="" /></p>
<ul>
<li>Q-functions expected value of rew</li>
<li>bottom term is the policy gradient</li>
<li>Advantage Functions
<ul>
<li>how much better it is</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/MQJYkvf.png" alt="" /></p>
<p><img src="https://i.imgur.com/lFJtqCC.png" alt="" /></p>
<ul>
<li>Actor-Critic Function?</li>
</ul>
<p><img src="https://i.imgur.com/kQj1Usk.png" alt="" /></p>
<ul>
<li>use a replace buffer to avoid bias</li>
<li>use a target network</li>
</ul>
<p><img src="https://i.imgur.com/XjLzegW.png" alt="" /></p>
<ul>
<li>two q functions</li>
</ul>
<h2><a class="header" href="#exploration-1" id="exploration-1">Exploration</a></h2>
<ul>
<li>optimistic exploration</li>
<li>posterior sampling</li>
<li>curiosity-driven exploration (model-based)</li>
<li>Information Bottleneck Methods</li>
</ul>
<h2><a class="header" href="#what-is-the-problem" id="what-is-the-problem">What is the Problem?</a></h2>
<p><img src="https://i.imgur.com/PrlBsgu.png" alt="" /></p>
<ul>
<li>Policy</li>
<li>Value-Based, you actually have to visit the state</li>
<li>Epsilon greedy sometimes choose random action</li>
</ul>
<p><img src="https://i.imgur.com/ITiJxXx.png" alt="" /></p>
<ul>
<li>random walk explores slowly</li>
</ul>
<p><img src="https://i.imgur.com/Wz79mAd.png" alt="" /></p>
<ul>
<li>Montezuma's Revenge is impossible
<ul>
<li>hard to randomly get key, avoid skull and get to the exit</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#exploration-vs-exploitation" id="exploration-vs-exploitation">Exploration vs Exploitation</a></h2>
<pre><code>* try new resturant
* go to best restaurant
</code></pre>
<h2><a class="header" href="#optimistic-exploration-in-rl" id="optimistic-exploration-in-rl">Optimistic Exploration in RL</a></h2>
<p><img src="https://i.imgur.com/U4JLoOe.png" alt="" /></p>
<ul>
<li><strong>Upper Confidence Bount</strong> (UCB)
<ul>
<li>num times we have visited state s</li>
<li>intrinsic reward for bonus</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#similar-states" id="similar-states">Similar States?</a></h2>
<p><img src="https://i.imgur.com/B0ZOYFl.png" alt="" /></p>
<ul>
<li>density of a state</li>
<li>updating the counts</li>
</ul>
<h2><a class="header" href="#exploring-with-pseudo-counts" id="exploring-with-pseudo-counts">Exploring with Pseudo-counts</a></h2>
<p><img src="https://i.imgur.com/IukNx9j.png" alt="" /></p>
<ul>
<li>pseudo count now have a n and N</li>
</ul>
<p><img src="https://i.imgur.com/iBrD3CF.png" alt="" /></p>
<ul>
<li>It's a generative model</li>
<li>PixelCNN is pretty good!</li>
</ul>
<h2><a class="header" href="#what-kind-of-bonus-to-use" id="what-kind-of-bonus-to-use">What kind of bonus to use?</a></h2>
<p><img src="https://i.imgur.com/KOmepsX.png" alt="" /></p>
<ul>
<li>UCB is good</li>
</ul>
<h2><a class="header" href="#posterior-sampling" id="posterior-sampling">Posterior Sampling</a></h2>
<p><img src="https://i.imgur.com/7w56Kuw.png" alt="" /></p>
<ul>
<li>uncertainty?
<ul>
<li>sample parameters (Thompson Sampling)</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#bootstrap" id="bootstrap">Bootstrap</a></h2>
<p><img src="https://i.imgur.com/7hif03q.png" alt="" /></p>
<ul>
<li>resample with replacement D_N samples
<ul>
<li>train model on each sample</li>
<li>to &quot;sample&quot; evaluate one of the models</li>
</ul>
</li>
<li>you can explore the parameter space with bootstrap samples</li>
<li>a trick is multihead learning, share the convolution layers</li>
</ul>
<p><img src="https://i.imgur.com/Pryjykv.png" alt="" /></p>
<ul>
<li>consistent for an entire episode (COMMIT TO THE CHOICE)</li>
</ul>
<h2><a class="header" href="#model-free-rl" id="model-free-rl">Model Free RL</a></h2>
<p><img src="https://i.imgur.com/JhsdfT4.png" alt="" /></p>
<ul>
<li>don't care about reward and transition</li>
</ul>
<h2><a class="header" href="#model-based-rl" id="model-based-rl">Model-based RL</a></h2>
<p><img src="https://i.imgur.com/ddSKt3U.png" alt="" /></p>
<ul>
<li>It helps!</li>
<li>Learn a latent space \( \phi(s) \)</li>
</ul>
<h2><a class="header" href="#curiosity-driven" id="curiosity-driven">Curiosity-driven</a></h2>
<p><img src="https://i.imgur.com/TAgyxSa.png" alt="" /></p>
<h2><a class="header" href="#intrinsic-curiosity-model-icm" id="intrinsic-curiosity-model-icm">Intrinsic Curiosity Model (ICM)</a></h2>
<p><img src="https://i.imgur.com/1iqIc8n.png" alt="" /></p>
<ul>
<li>useful embedding</li>
<li>latent space to learn an inverse function</li>
</ul>
<p><img src="https://i.imgur.com/XM7wFYb.png" alt="" /></p>
<ul>
<li>?</li>
</ul>
<p><img src="https://i.imgur.com/sYEyQTN.png" alt="" /></p>
<ul>
<li>works really well!</li>
</ul>
<h2><a class="header" href="#information-bottleneck-approaches" id="information-bottleneck-approaches">Information Bottleneck Approaches</a></h2>
<p><img src="https://i.imgur.com/qMoalV5.png" alt="" /></p>
<ul>
<li>make it as minimal as possible</li>
</ul>
<h2><a class="header" href="#mutal-information" id="mutal-information">Mutal Information</a></h2>
<ul>
<li><strong>Mutual Information</strong>: joint distribution?</li>
</ul>
<p><img src="https://i.imgur.com/LGzajmO.png" alt="" /></p>
<p><img src="https://i.imgur.com/LAlolmh.png" alt="" /></p>
<ul>
<li>Latent layer Z, it's a distribution but in a network it's deterministic</li>
</ul>
<p><img src="https://i.imgur.com/teuEH1l.png" alt="" /></p>
<ul>
<li>want to minimize redundant info</li>
</ul>
<p><img src="https://i.imgur.com/V0CvkyB.png" alt="" /></p>
<ul>
<li>better generalization</li>
</ul>
<p><img src="https://i.imgur.com/i1k7ut9.png" alt="" /></p>
<h2><a class="header" href="#information-bottleneck-for-rl" id="information-bottleneck-for-rl">Information Bottleneck for RL</a></h2>
<p><img src="https://i.imgur.com/YS1LKvh.png" alt="" /></p>
<ul>
<li>subpolicy</li>
</ul>
<p><img src="https://i.imgur.com/zQVqSRs.png" alt="" /></p>
<ul>
<li>Learns to move on the skeleton (vertices)</li>
<li>from infinite number of decisions to a small finite number of them</li>
</ul>
<h2><a class="header" href="#adversarial-information-bottlenecks" id="adversarial-information-bottlenecks">Adversarial Information Bottlenecks</a></h2>
<p><img src="https://i.imgur.com/ciql9m7.png" alt="" /></p>
<ul>
<li>train mutual info and detect the bottleneck</li>
</ul>
<p><img src="https://i.imgur.com/Fj24lYe.png" alt="" /></p>
<ul>
<li>rip</li>
</ul>
<p><img src="https://i.imgur.com/RGeKtMV.png" alt="" /></p>
<ul>
<li>learn where you don't need to take actions but eventually states with high I</li>
</ul>
<h2><a class="header" href="#questions" id="questions">Questions</a></h2>
<ul>
<li>What to review</li>
</ul>
<h1><a class="header" href="#other-resources" id="other-resources">Other Resources</a></h1>
<h1><a class="header" href="#visualizing-seq2seq-with-attention" id="visualizing-seq2seq-with-attention">Visualizing Seq2Seq with Attention</a></h1>
<p><a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">Link</a></p>
<h2><a class="header" href="#review-of-visual-attention" id="review-of-visual-attention">Review of Visual Attention</a></h2>
<p><img src="https://i.imgur.com/GpIFcPF.png" alt="" /></p>
<ul>
<li>Have Image (top) and location <code>l_t-1</code> fed into <code>f_g</code> glimpse network.</li>
<li>This is fed into a recurrent network <code>f_h</code></li>
<li>The output hidden state is fed into two networks
<ul>
<li><code>f_a</code> activation network which does the prediction</li>
<li><code>f_l</code> location network which predicts the next location <code>l_t</code>. In Soft Attention this is done with a saliency map.</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/3lZj6UK.png" alt="" /></p>
<ul>
<li>The model has an <strong>encoder</strong> and <strong>decoder</strong></li>
<li><strong>Context</strong> is transfered from the encoder to the decoder
<ul>
<li>Context is a vector of floats. It is a hidden state in a RNN</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/IVCpWGs.png" alt="" /></p>
<ul>
<li>The words are embedded as vectors using a <strong>word embedding</strong> algorithm.</li>
</ul>
<h3><a class="header" href="#at-attention" id="at-attention">At Attention!</a></h3>
<ul>
<li><strong>Attention</strong> is the idea some words are more important than others when getting the translation
<ul>
<li>Caf to coffee</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/VviBRGt.png" alt="" /></p>
<ul>
<li>Instead of one hidden state, pass all the hidden states!</li>
</ul>
<p><img src="https://i.imgur.com/R0V8kgM.png" alt="" /></p>
<ul>
<li>Use the decoder hidden state to score encoder hidden states. This is  <strong>attention</strong>.</li>
</ul>
<p><img src="https://i.imgur.com/a012seQ.png" alt="" /></p>
<ul>
<li><code>h_4</code> : hidden state and <code>c_4</code> : context state are concated and the output word comes out</li>
<li>Where does the scoring happen though?</li>
</ul>
<h2><a class="header" href="#from-lecture" id="from-lecture">From Lecture</a></h2>
<p><img src="https://i.imgur.com/ZETrFIt.png" alt="" /></p>
<ul>
<li>In lecture, it is weighed alignment scores</li>
<li>alignment score: \( \text{score}(\boldsymbol{s}_t, \boldsymbol{h}_i) = \mathbf{v}_a^\top \tanh(\mathbf{W}_a[\boldsymbol{s}_t; \boldsymbol{h}_i]) \)
<ul>
<li>\( \mathbf{v}_a \) and \( \mathbf{W}_a \) are weights that can be learned</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/RFYS1Xt.png" alt="" /></p>
<ul>
<li>Combine current recurrent state and all input states into attention weight (soft-attention) of input states. The attention weight adds up to 1, and is done with a softmax. </li>
</ul>
<h1><a class="header" href="#visualizing-transformers" id="visualizing-transformers">Visualizing Transformers</a></h1>
<p><a href="http://jalammar.github.io/illustrated-transformer/">Link</a></p>
<h2><a class="header" href="#high-level" id="high-level">High Level</a></h2>
<p><img src="https://i.imgur.com/EjK8hNc.png" alt="" /></p>
<ul>
<li>In the transformer black box we have an <strong>encoder</strong> and <strong>decoder</strong></li>
</ul>
<p><img src="https://i.imgur.com/DN6ElwE.png" alt="" /></p>
<ul>
<li>The encoders are stacked on top of each other.</li>
</ul>
<h3><a class="header" href="#encoders" id="encoders">Encoders</a></h3>
<p><img src="https://i.imgur.com/NZ8mlKa.png" alt="" /></p>
<ul>
<li>The encoder block is made of a <strong>self-attention</strong> layer and <strong>feed-forward network</strong>
<ul>
<li>self-attention helps the encoder look at words in the input sentence as it encodes a specific word</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/7W5GDqK.png" alt="" /></p>
<ul>
<li>In NLP, each word is embedded as a vector</li>
<li>list of word vectors is a tensor</li>
</ul>
<p><img src="https://i.imgur.com/E6136r3.png" alt="" /></p>
<p><img src="https://i.imgur.com/8jThN0h.png" alt="" /></p>
<h3><a class="header" href="#self-attention" id="self-attention">Self-Attention</a></h3>
<ul>
<li>The feed-forward layer is actually one network that is reused by each \( Z_i \) encoded vector. That is like a convolution</li>
</ul>
<p><img src="https://i.imgur.com/Vqn2VSb.png" alt="" /></p>
<ul>
<li>Say you have the sentence &quot;The animal didn't cross the street because it was too tired.&quot; What does <strong>it</strong> refer to? In this case, &quot;The animal.&quot; A self-attention layer lets the network learn this representation.</li>
</ul>
<p><img src="https://i.imgur.com/unpaPfS.png" alt="" /></p>
<ul>
<li>We have the embedded words (green \( X_i \))</li>
<li>For each word, we want to get out a <strong>queries</strong> vector, a <strong>keys</strong> vector, and a <strong>values</strong> vector. We have learnable weights \( W^Q \), \( W^K \), and \( W^V \).</li>
<li>The matrix multiplication of the green embedded word and the queries matrix, keys matrix, and values matrix create the queries vector, keys vector, and values vector for each word.</li>
</ul>
<p><img src="https://i.imgur.com/jsas4BF.png" alt="" /></p>
<ul>
<li>For each word, we calculate a score using the queries vector and keys vector.</li>
</ul>
<p><img src="https://i.imgur.com/LpzehcO.png" alt="" /></p>
<ul>
<li>We divide by 8 (sqrt of dim of keys vector for stable gradients) and take the softmax over all words (in a batch? in the corpus?)
<ul>
<li>(self-attention seems to be over a batch)</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/o2gTn7S.png" alt="" /></p>
<ul>
<li>We multiply the softmax by the value and sum up all the weighted value vector \( V_i \)
<ul>
<li>(Does this mean all \( Z_i \) are equal though?)</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#self-attention-as-matrices" id="self-attention-as-matrices">Self-Attention as Matrices</a></h3>
<p><img src="https://i.imgur.com/CmSRI5r.png" alt="" /></p>
<ul>
<li>Batch of two words, embedded in a vector of size 2.</li>
<li>(Each weight matrix is the same size though?)</li>
</ul>
<p><img src="https://i.imgur.com/eVmtrMH.png" alt="" /></p>
<ul>
<li>Q, K, and V are calculated from X (They are NOT the weight matrices!)</li>
<li>Their operation can be condensed into one formula</li>
</ul>
<h3><a class="header" href="#multi-head-attention" id="multi-head-attention">Multi-head Attention</a></h3>
<p><img src="https://i.imgur.com/63q1zFr.png" alt="" /></p>
<ul>
<li>Instead of just using one Q, K, and V weight we can use multiple!</li>
<li>This is like multiple filters in a convolution.</li>
</ul>
<p><img src="https://i.imgur.com/vaVBv2C.png" alt="" /></p>
<ul>
<li>To combine the multiple heads into a single head for the feed-forward network, we can concat all the heads \( Z_i \) and multiply it by a weight matrix \( W^O \)</li>
</ul>
<p><img src="https://i.imgur.com/vyxHEn7.png" alt="" /></p>
<ul>
<li>Each step shown together
<ul>
<li>The input to self-attention does not have to be a batch of words (green matrix \( X \)) but it can be the output of an encoder below (blue matrix \( R \)). Encoders are stacked.</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/7RDKhZK.png" alt="" /></p>
<ul>
<li>At the top is a bunch of colors. They represent heads. The blue head for the word &quot;it_&quot; has attention at &quot;street&quot;, &quot;'<em>&quot;, and &quot;because&quot;. The green head has attention at &quot;tire&quot;, &quot;d</em>&quot;, and &quot;was_&quot;.</li>
</ul>
<h3><a class="header" href="#positional-encoding" id="positional-encoding">Positional Encoding</a></h3>
<p><img src="https://i.imgur.com/6nL9QBu.png" alt="" /></p>
<ul>
<li>To encode position, we add positional encoding with our embedded word vectors</li>
</ul>
<p><img src="https://i.imgur.com/KJy5mug.png" alt="" /></p>
<ul>
<li>The encoding is done with sin and cosine. Not much detail is added (@TODO go back to this in the lecture)</li>
</ul>
<h3><a class="header" href="#residuals-in-the-encoder" id="residuals-in-the-encoder">Residuals in the Encoder</a></h3>
<p><img src="https://i.imgur.com/ObpOAHt.png" alt="" /></p>
<ul>
<li>Like ResNet, Residuals are useful in Transformers.</li>
</ul>
<p><img src="https://i.imgur.com/856SQJe.png" alt="" /></p>
<ul>
<li>The pre-attention vectors and post-attention vectors are added together and normalized like batch norm</li>
</ul>
<h2><a class="header" href="#decoder" id="decoder">Decoder</a></h2>
<p><img src="https://i.imgur.com/ZttEnYU.png" alt="" /></p>
<ul>
<li>The output vectors of the encoder are transformed into Key and Value matrices (not weights?) in the Decoder sequence</li>
<li>The Decoder has to create it's own Queries matrix</li>
<li>They are used by each Decoder (why?)</li>
</ul>
<p><img src="https://i.imgur.com/4O6WuNr.png" alt="" /></p>
<ul>
<li>The previous input is fed into the decoder. The positional encoding is added again to this output</li>
</ul>
<p><img src="https://i.imgur.com/51kvlQj.png" alt="" /></p>
<ul>
<li>The output embedded vector is matrix mutliplied to the vocab_size. It goes through a softmax, where the large index is the chosen word.</li>
</ul>
<h2><a class="header" href="#training" id="training">Training</a></h2>
<p><img src="https://i.imgur.com/vlzyFKr.png" alt="" /></p>
<ul>
<li>The data is matrix of batch size times one hot encoding and the true value is the same.</li>
<li>In training we can keep the top k best predictions at each word. And feed best next words into the decoder. This is <strong>beam search</strong></li>
</ul>
<h1><a class="header" href="#visualizing-bert-elmo-and-gpt" id="visualizing-bert-elmo-and-gpt">Visualizing BERT, ELMo, and GPT</a></h1>
<p><a href="http://jalammar.github.io/illustrated-bert/">Link</a></p>
<p><img src="https://i.imgur.com/vaB3saH.png" alt="" /></p>
<ul>
<li>Step 1 is to semi-supervise on large amounts of task. Usually predicting masked words.</li>
<li>Step 2 is to fine grain train on a dataset</li>
</ul>
<p><img src="https://i.imgur.com/ICfXukJ.png" alt="" /></p>
<ul>
<li>BERT then with a fine grain spam classifier</li>
</ul>
<p><img src="https://i.imgur.com/R5YLWxl.png" alt="" /></p>
<ul>
<li>BERT is a encoder transformer stack</li>
</ul>
<h2><a class="header" href="#word-embeddings-and-elmo" id="word-embeddings-and-elmo">Word Embeddings and ELMo</a></h2>
<p><img src="https://i.imgur.com/wNFFOZc.jpg" alt="" /></p>
<ul>
<li>ELMo uses contextual (where in the sentence) to embedded.</li>
</ul>
<p><img src="https://i.imgur.com/Ynzilsc.png" alt="" /></p>
<ul>
<li>ELMo predicts the next likely word</li>
</ul>
<p><img src="https://i.imgur.com/ZNU7ol2.png" alt="" /></p>
<ul>
<li>ELMo also includes information of the next words in a sentence/batch. The forward and backward LSTM are concatenated together</li>
</ul>
<h2><a class="header" href="#openai-transformer" id="openai-transformer">OpenAI Transformer</a></h2>
<ul>
<li>It uses only the transformer decoder</li>
</ul>
<p><img src="https://i.imgur.com/7feXECY.png" alt="" /></p>
<ul>
<li>Predict the next word</li>
</ul>
<p><img src="https://i.imgur.com/ddFdSrJ.png" alt="" /></p>
<ul>
<li>Transfer Learn!</li>
</ul>
<p><img src="https://i.imgur.com/bUgDTmk.png" alt="" /></p>
<ul>
<li>More Transfer Learning. Often with tasks, the structure of inputs is important</li>
</ul>
<h2><a class="header" href="#bert-1" id="bert-1">BERT</a></h2>
<p><img src="https://i.imgur.com/MtcxjTT.png" alt="" /></p>
<ul>
<li>15% of words are masked. BERT tries to predict the masked word</li>
</ul>
<p><img src="https://i.imgur.com/NzChyLx.png" alt="" /></p>
<ul>
<li>An additional task was to predict if a given sentence was followed by another given sentence</li>
</ul>
<p><img src="https://i.imgur.com/UN4nCpS.png" alt="" /></p>
<ul>
<li>BERT transfer learning</li>
</ul>
<p><img src="https://i.imgur.com/4kqLRhK.png" alt="" /></p>
<ul>
<li>BERT can do word embeddings</li>
</ul>
<p><img src="https://i.imgur.com/qB1f52C.png" alt="" /></p>
<ul>
<li>F1 score decreases the deeper the network. Deeper should give better embeddings.</li>
</ul>
<h1><a class="header" href="#review-cs-188-ai" id="review-cs-188-ai">Review CS 188: AI</a></h1>
<p><a href="https://docs.google.com/presentation/d/1KVQq4llaJA7beVuIhE-8DvFKbq1w5Hdtjuzv4nYkJZc/edit?usp=sharing">Link</a></p>
<h2><a class="header" href="#markov-decision-processes" id="markov-decision-processes">Markov Decision Processes</a></h2>
<ul>
<li>Starts on Slide 38</li>
</ul>
<p><img src="https://i.imgur.com/Kj265qE.png" alt="" /></p>
<ul>
<li>states, choose an action (slow or fast), then it <strong>non-deterministic</strong> goes to another state. reward gained when entering the state
<ul>
<li>look at overheated, -10 reward!</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/k3mmXTH.png" alt="" /></p>
<ul>
<li>If you know the reward and transition functions
<ul>
<li>You can solve the MDP with Value/Policy Iteration</li>
</ul>
</li>
<li>Else you solve it with Reinforcement Learning
<ul>
<li>Model Based RL or Model Free RL</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#bellman-equation" id="bellman-equation">Bellman Equation</a></h2>
<p><img src="https://i.imgur.com/0rCUf7s.png" alt="" /></p>
<ul>
<li>\(V^{*}(s) \) is the <strong>value</strong> of a state if acting optimally</li>
<li>\(Q^{*}(s, a) \) Q is the value of taking action a in state s, and acting optimally after</li>
<li>\( V^*(s) = \max_a Q^*(s, a)\)</li>
</ul>
<p><img src="https://i.imgur.com/CWULp54.png" alt="" /></p>
<ul>
<li>At the end of the V and Q equation is a V and Q. They are equivalent</li>
</ul>
<h2><a class="header" href="#value-iteratio" id="value-iteratio">Value Iteratio</a></h2>
<p><img src="https://i.imgur.com/Wao7fpm.png" alt="" /></p>
<ul>
<li>N iterations, recursively solve down the graph. converges to correct answer</li>
</ul>
<h2><a class="header" href="#policies" id="policies">Policies</a></h2>
<p><img src="https://i.imgur.com/QmLvPp1.png" alt="" /></p>
<ul>
<li>\(V^\pi\) value of state using policy \( \pi \). It determines the action</li>
<li>now do a single action instead of all actions</li>
<li>goal learn best policy!</li>
</ul>
<h2><a class="header" href="#optimal-policy" id="optimal-policy">Optimal Policy</a></h2>
<p><img src="https://i.imgur.com/dAdpszv.png" alt="" /></p>
<ul>
<li>the optimal policy chooses the action that maximizes future reward?</li>
<li>the optimal policy value should equal the optimal value?</li>
</ul>
<h2><a class="header" href="#policy-iteration" id="policy-iteration">Policy Iteration</a></h2>
<p><img src="https://i.imgur.com/gp22GHc.png" alt="" /></p>
<ul>
<li>inner loop learns the value of policy pi.</li>
<li>outerloop update for best policy pi</li>
</ul>
<p><img src="https://i.imgur.com/EPwLMvg.png" alt="" /></p>
<h2><a class="header" href="#reinforcement-learning-1" id="reinforcement-learning-1">Reinforcement Learning</a></h2>
<ul>
<li>when you don't have reward and transition functions </li>
</ul>
<h3><a class="header" href="#model-based-rl-1" id="model-based-rl-1">Model Based RL</a></h3>
<ul>
<li>try to estimate
<ul>
<li>transition func: \( T(s, a, s') \)</li>
<li>reward func: \( R(s, a, s') \)</li>
</ul>
</li>
<li>now do policy iteration or value iteration!</li>
</ul>
<h3><a class="header" href="#model-free-rl-1" id="model-free-rl-1">Model Free RL</a></h3>
<ul>
<li>basically yolo and learn</li>
<li>&quot;take an action and <strong>see what happens</strong>&quot;</li>
<li>learn what actions are good even if you don't know <strong>why</strong> they are good
<ul>
<li>(don't know the transitions and rewards)</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#temporal-difference-td-learning" id="temporal-difference-td-learning">Temporal Difference (TD) Learning</a></h3>
<ul>
<li>passive (fixed policy) RL</li>
</ul>
<p><img src="https://i.imgur.com/5FRBdk5.png" alt="" /></p>
<ul>
<li>just take a sample of state, policy, next state, and reward
<ul>
<li>v is reward and discount of future value</li>
<li>update our policy value for that state with an exponential moving average</li>
</ul>
</li>
<li>good for learning V-values but not policies</li>
<li>does not track <strong>all</strong> v-values</li>
<li>doesn't know about unvisited states</li>
</ul>
<h3><a class="header" href="#q-learning" id="q-learning">Q-learning</a></h3>
<ul>
<li>active (online?)</li>
</ul>
<p><img src="https://i.imgur.com/uS6KjNe.png" alt="" /></p>
<ul>
<li>update Q</li>
</ul>
<h3><a class="header" href="#exploration-vs-exploitation-1" id="exploration-vs-exploitation-1">Exploration vs Exploitation</a></h3>
<ul>
<li>epsilon-greedy, random policy with small epsilon, our learned policy wtih 1-epsilon</li>
</ul>
<h3><a class="header" href="#approximate-q-learning" id="approximate-q-learning">Approximate Q-Learning</a></h3>
<p><img src="https://i.imgur.com/w4eNIMu.png" alt="" /></p>
<ul>
<li><strong>feature based Q-learning</strong></li>
</ul>
<p><img src="https://i.imgur.com/CoG6arI.png" alt="" /></p>
<ul>
<li>don't learn Q-Values directly learn the weights</li>
</ul>
<p><img src="https://i.imgur.com/x28q7v3.png" alt="" /></p>
<ul>
<li>find the difference and update the q function?</li>
</ul>
<p><img src="https://i.imgur.com/Qc4a7IE.png" alt="" /></p>
<ul>
<li>instead use the difference to learn the weights</li>
</ul>
<h2><a class="header" href="#questions-1" id="questions-1">Questions</a></h2>
<ul>
<li>Is Online On-policy and off-policy?</li>
</ul>
<h1><a class="header" href="#homeworks" id="homeworks">Homeworks</a></h1>
<h1><a class="header" href="#homework-2-rnn-and-lstm" id="homework-2-rnn-and-lstm">Homework 2 RNN and LSTM</a></h1>
<ul>
<li><a href="https://bcourses.berkeley.edu/courses/1487769/pages/assignment-2-description">Link</a></li>
<li><a href="https://briantliao.com/store/cs282-lectures-slides/lec09.pdf">RNN and LSTM lecture slides</a></li>
</ul>
<h2><a class="header" href="#setup" id="setup">Setup</a></h2>
<pre><code class="language-sh">conda install &quot;tensorflow&lt;2.0&quot;          # cpu version
conda install &quot;tensorflow-gpu&lt;2.0&quot;      # gpu version
# I think I will use PyTorch though

conda create -n cs182-assignment2  
conda activate cs182-assignment2
# to deactivate:  conda deactivate

pip3 install -r requirements.txt # @Brian changed to pip3
</code></pre>
<h3><a class="header" href="#gpus" id="gpus">GPUs</a></h3>
<p>GPUs are not required for this assignment, but will help to speed up training and processing time for questions 3-4.</p>
<h3><a class="header" href="#download-data" id="download-data">Download Data</a></h3>
<pre><code class="language-sh">cd deeplearning/datasets
./get_assignment2_data.sh
</code></pre>
<p>Now you can use Jupyter Notebook <code>jupyter serve</code>!</p>
<h2><a class="header" href="#q1-image-captioning-with-vanilla-rnns-30-points" id="q1-image-captioning-with-vanilla-rnns-30-points">Q1: Image Captioning with Vanilla RNNs (30 points)</a></h2>
<p><img src="https://i.imgur.com/dysQhPY.png" alt="" /></p>
<ul>
<li>RNN Equation</li>
</ul>
<p>b included before tanh:
<code>sum_together = dot_x + dot_h + b</code></p>
<h2><a class="header" href="#q2-image-captioning-with-lstms-30-points" id="q2-image-captioning-with-lstms-30-points">Q2: Image Captioning with LSTMs (30 points)</a></h2>
<ul>
<li>\( \odot \) is the elementwise product of vectors.</li>
<li><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTMs</a></li>
</ul>
<p><img src="https://i.imgur.com/5LFX2M2.png" alt="" /></p>
<ul>
<li>RNN</li>
</ul>
<p><img src="https://i.imgur.com/OHAy8uM.png" alt="" /></p>
<ul>
<li>LSTM</li>
</ul>
<p>LSTM backwards</p>
<h2><a class="header" href="#q3-network-visualization-saliency-maps-class-visualization-and-fooling-images-20-points" id="q3-network-visualization-saliency-maps-class-visualization-and-fooling-images-20-points">Q3: Network Visualization: Saliency maps, Class Visualization, and Fooling Images (20 points)</a></h2>
<h3><a class="header" href="#saliency" id="saliency">Saliency</a></h3>
<p><img src="https://i.imgur.com/agqsFrM.png" alt="" /></p>
<ul>
<li>Which pixel has the most effect on the input</li>
</ul>
<p><img src="https://i.imgur.com/a1XejED.png" alt="" /></p>
<ul>
<li>
<p>A <strong>saliency map</strong> tells us the degree to which each pixel in the image affects the classification score for that image. To compute it, we compute the gradient of the unnormalized score (?) corresponding to the correct class (which is a scalar) (why is this a scalar?) with respect to the pixels of the image.</p>
</li>
<li>
<p>If the image has shape (3, H, W) then this gradient will also have shape (3, H, W); for each pixel in the image, this gradient tells us the amount by which the classification score will change if the pixel changes by a small amount. </p>
</li>
<li>
<p>To compute the saliency map, we take the absolute value of this gradient, then take the maximum value over the 3 input channels; the final saliency map thus has shape (H, W) and all entries are nonnegative.</p>
</li>
<li>
<p>@Brian: gradient of what? Max of what?</p>
</li>
<li>
<p><a href="http://pytorch.org/docs/torch.html#torch.gather">Pytorch Gather</a></p>
</li>
<li>
<p><code>s.gather(1, y.view(-1, 1)).squeeze()</code></p>
<ul>
<li>turns out to be like a loss. Cross entropy <code>mean()</code></li>
</ul>
</li>
</ul>
<h4><a class="header" href="#fooling-network" id="fooling-network">Fooling Network</a></h4>
<ul>
<li><code>torch.Tensor.data</code> and <code>torch.Tensor.grad.data</code></li>
<li>do not update <code>torch.Tensor += torch.Tensor</code> when we are returning a copy, <code>torch.Tensor.copy()</code></li>
<li>gradient ascent <code>torch.Tensor += torch.Tensor</code> wild</li>
<li>we calculate our own loss????</li>
</ul>
<h2><a class="header" href="#q4-style-transfer-20-points" id="q4-style-transfer-20-points">Q4: Style Transfer (20 points)</a></h2>
<h2><a class="header" href="#debugging" id="debugging">Debugging</a></h2>
<p>List Conda Enviornments:</p>
<pre><code>conda env list
</code></pre>
<p>Trying without conda env.</p>
<pre><code>pip install scipy==1.1.0
</code></pre>
<h2><a class="header" href="#tips-and-notes" id="tips-and-notes">Tips and Notes</a></h2>
<h3><a class="header" href="#numpy" id="numpy">Numpy</a></h3>
<pre><code class="language-python">np.zeros_like( another numpy array )

A.shape # (3, 4)
B.shape # (4, 4)
np.dot(A, B).shape # (3, 4)

np.zeros((dim1, dim2, dim3))

 x_pad[n,:,y_padded:y_padded+HH,x_padded:x_padded+WW]

 x[0,0,0] # indexes a single value
 x[0:5, 1:4, 6:8] # slices a tensor

x[-1] == x[len(x) - 1] 

# let x in 10 elements, index 0 to 9
for i in range(x - 1, -1, -1):
    print(i)
# 9, 8, 7 ... 2, 1, 0

</code></pre>
<h3><a class="header" href="#calculus" id="calculus">Calculus</a></h3>
<h3><a class="header" href="#chain-rule" id="chain-rule">Chain Rule:</a></h3>
<p>$$ \frac{\partial L}{\partial x} = \frac{\partial L}{\partial y} \frac{\partial y}{\partial x} $$</p>
<p>Same for \( \frac{\partial L}{\partial b} \) and \( \frac{\partial L}{\partial W} \).</p>
<p>We have \( \frac{\partial L}{\partial y} \) and we can solve for \( \frac{\partial y}{\partial y} \) locally. This may need values cached from the forward pass.</p>
<h1><a class="header" href="#homework-3-natural-language-processing" id="homework-3-natural-language-processing">Homework 3 Natural Language Processing</a></h1>
<p>Add to jupyter:</p>
<pre><code class="language-python">%reload_ext autoreload
%autoreload 2
</code></pre>
<p><a href="https://drive.google.com/open?id=1TNhUy9ldZ5mv_GLNNmCBFnLfT3DXwntF">Add to Google Colab</a></p>
<p><img src="https://i.imgur.com/5Rz14EN.png" alt="" /></p>
<ul>
<li>Attention</li>
</ul>
<p><img src="https://i.imgur.com/imbD4vw.png" alt="" /></p>
<ul>
<li>MultiHead</li>
</ul>
<h2><a class="header" href="#transformer-1" id="transformer-1">Transformer</a></h2>
<p><code>transformer_attention.py</code>:</p>
<pre><code class="language-python">from typing import Optional, Callable, Tuple

import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.layers import Layer

from transformer_layers import WeightNormDense as Dense, LayerNorm, ApplyAttentionMask

class AttentionQKV(Model):
    &quot;&quot;&quot;
    Computes attention based on provided similarity metric.
    &quot;&quot;&quot;

    def __init__(self) -&gt; None:
        super().__init__()
        self.apply_mask = ApplyAttentionMask()

    def call(self, queries, keys, values, mask=None):
        &quot;&quot;&quot;Fast scaled dot product attention.

            :param queries: Tensor with shape [batch_size, heads (optional), n_queries, depth_k]
            :param keys:    Tensor with shape [batch_size, heads (optional), n_keyval, depth_k]
            :param values:  Tensor with shape [batch_size, heads (optional), n_keyval, depth_v]
            :param mask:    Tensor with shape [batch_size, n_queries, n_queries]

            :return: output: Tensor with shape [batch_size, heads (optional), n_queries, depth_v]
        &quot;&quot;&quot;
        ####################################  YOUR CODE HERE  ####################################
        # n_queries corresponds to the sequence length on the query side @Brian
        # n_keyval corresponds to the sequence length on the key side (and value, as they are one and the same)
        # depth_k is the size of the projection that the key / query comparison is performed on.
        # depth_v is the size of the projection of the value projection. In a setting with one head, it is usually the dimension (dim) of the Transformer.
        # heads corresponds to the number of heads the attention is performed on.
        # If you are unfamiliar with attention heads, read section 3.2.2 of the Attention is all you need paper

        # PART 1: Implement Attention QKV

        # Use queries, keys and values to compute the output of the QKV attention

        # As defined is the Attention is all you need paper: https://arxiv.org/pdf/1706.03762.pdf
        key_dim = tf.cast(tf.shape(keys)[-1], tf.float32)
        similarity = 1/tf.sqrt(key_dim) # Compute the similarity according to the QKV formula

        masked_similarity = self.apply_mask(similarity, mask=mask) # We give you the mask to apply so that it is correct, you do not need to modify this.
        weights = None # Turn the similarity into a normalized output
        output = None # Obtain the output
        print('hello world!')
        ####################################  END OF YOUR CODE  ##################################

        return output, weights


class MultiHeadProjection(Model):

    def __init__(self, n_heads) -&gt; None:
        &quot;&quot;&quot;Map the multi-headed attention across the map

        Arguments:
            similarity_metric {[type]} -- The metric that should be used for the similarity
            n_heads {int} -- The number of heads in the attention map

        &quot;&quot;&quot;

        super().__init__()
        self.attention_map = AttentionQKV()
        self.n_heads = n_heads

    def build(self, input_shape):
        for shape in input_shape:
            assert shape[-1] % self.n_heads == 0, 'Shape of feature input must be divisible by n_heads'

    def call(self, inputs, mask=None):
        &quot;&quot;&quot;Fast multi-head attention.

        :param queries: Tensor with shape [batch_size, n_queries, depth_k]
        :param keys:    Tensor with shape [batch_size, n_keyval, depth_k]
        :param values:  Tensor with shape [batch_size, n_keyval, depth_v]

        :return: output: Tensor with shape [batch_size, n_queries, depth_v]
        &quot;&quot;&quot;
        queries, keys, values = inputs

        # Split each of the projection into its heads, by adding a new dimension
        # You must implement _split_heads, and _combine_heads
        queries_split = self._split_heads(queries)
        keys_split = self._split_heads(keys)
        values_split = self._split_heads(values)

        # Apply the attention map
        attention_output_split, _ = self.attention_map(queries_split, keys_split, values_split, mask=mask)

        # Re-combine the heads together, and return the output.
        output = self._combine_heads(attention_output_split)
        return output

    def _split_heads(self, tensor):
        tensor.shape.assert_has_rank(3)
        ####################################  YOUR CODE HERE  ####################################
        # PART 2: Implement the Multi-head attention.
        # You are given a Tensor which is one of the projections (K, Q or V)
        # and you must &quot;split it&quot; in self.n_heads. This splitting should add a dimension to the tensor,
        # so that each head acts independently

        batch_size, tensorlen = tf.shape(tensor)[0], tf.shape(tensor)[1]
        feature_size = tensor.shape.as_list()[2]

        new_feature_size = None # Compute what the feature size per head is.
        # Reshape this projection tensor so that it has n_heads, each of new_feature_size
        tensor = None
        # Transpose the matrix so the outer-dimensions are the batch-size and the number of heads
        tensor = None
        return tensor
        ##########################################################################################

    def _combine_heads(self, tensor):
        tensor.shape.assert_has_rank(4)
        ####################################  YOUR CODE HERE  ####################################
        # PART 2: Implement the Multi-head attention.
        # You are given the output from all the heads, and you must combine them back into 1 rank-3 matrix

        # Transpose back compared to the split, so that the outer dimensions are batch_size and sequence_length again
        tensor = None
        batch_size, tensorlen = tf.shape(tensor)[0], tf.shape(tensor)[1]
        feature_size = tensor.shape.as_list()[-1]

        new_feature_size = None # What is the new feature size, if we combine all the heads
        tensor = None # Reshape the Tensor to remove the heads dimension and come back to a Rank-3 tensor
        return tensor
        ##########################################################################################

class MultiHeadAttention(Model):
    &quot;&quot;&quot;
    Fast multi-head attention. Based on the Attention is All You Need paper.

    https://arxiv.org/pdf/1706.03762.pdf
    &quot;&quot;&quot;

    def __init__(self, n_heads) -&gt; None:
        super().__init__()

        self.n_heads = n_heads
        self.attention_layer = MultiHeadProjection(n_heads)

    def build(self, input_shapes):
        query_antecedent_shape, memory_antecedent_shape = input_shapes
        self.qa_channels = query_antecedent_shape[-1]
        self.ma_channels = memory_antecedent_shape[-1]
        assert self.qa_channels % self.n_heads == 0 and self.ma_channels % self.n_heads == 0, \
            'Feature size must be divisible by n_heads'
        assert self.qa_channels == self.ma_channels, 'Cannot combine tensors with different shapes'

        self.query_layer = Dense(self.qa_channels, use_bias=False)
        self.key_layer = Dense(self.qa_channels, use_bias=False)
        self.value_layer = Dense(self.ma_channels, use_bias=False)

        self.output_layer = Dense(self.qa_channels, use_bias=False)


    def call(self, inputs, mask=None):
        &quot;&quot;&quot;Fast multi-head self attention.

            :param inputs: tuple of (query_antecedent, memory_antecedent)
                query_antecedent -&gt; tensor w/ shape [batch_size, n_queries, channels]
                memory_antecedent -&gt; tensor w/ shape [batch_size, n_keyval, channels]
        &quot;&quot;&quot;
        assert isinstance(inputs, tuple) or isinstance(inputs, list) and len(inputs) == 2, \
            'Must pass query and memory'
        query_antecedent, memory_antecedent = inputs
        q = self.query_layer(query_antecedent)
        k = self.key_layer(memory_antecedent)
        v = self.value_layer(memory_antecedent)

        attention_output = self.attention_layer((q, k, v), mask=mask)
        output = self.output_layer(attention_output)
        return output
</code></pre>
<h1><a class="header" href="#section" id="section">Section</a></h1>
<h1><a class="header" href="#section-5-attention-mechanisms-and-transformers" id="section-5-attention-mechanisms-and-transformers">Section 5: Attention Mechanisms and Transformers</a></h1>
<h2><a class="header" href="#attention" id="attention">Attention</a></h2>
<ul>
<li>What is Attention?
<ul>
<li>it helps the network focus (weigh) parts of data more</li>
<li>in an RNN, this can focus not only on the past hiddel states</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/3WN6ja2.png" alt="" /></p>
<ul>
<li>What is Luong Attention?
<ul>
<li>it computes alignment weights \( a_t \) with alignment socres into a context vector \( c_t \)</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/FdoBhEI.png" alt="" /></p>
<ul>
<li>What is the output?
<ul>
<li>\( \tilde{h_t}=\tanh(W_f \cdot [h_t ; c_t]) \)</li>
<li>the \( [h_t ; c_t]) \) is concat</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#scaled-dot-productkey-query-value-attention-in-transformer-networks" id="scaled-dot-productkey-query-value-attention-in-transformer-networks">Scaled Dot-Product/Key-Query-Value Attention in Transformer Networks</a></h2>
<ul>
<li>What Attention is in Transformers?
<ul>
<li>Scaled Dot-Product/Key-Query-Value Attention</li>
<li>It has K, Q, V</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/Fw10Ej9.png" alt="" /></p>
<ul>
<li>What is the product of Query Q and Key K?
<ul>
<li>the  dot product is a score</li>
</ul>
</li>
<li>What is the interpretation of Q?
<ul>
<li>it is a querying term to find it's relation to K and V pair</li>
<li>we get a score for each K for each Q.</li>
</ul>
</li>
<li>Where do you get attention weights?
<ul>
<li>After softmaxing them all!</li>
</ul>
</li>
<li>What do you do with the values?
<ul>
<li>Multiply with the weights!</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/rpdlpIP.png" alt="" /></p>
<ul>
<li>
<p>What is the correspondence to Luong Attention?</p>
<ul>
<li>Q query &lt;-&gt; \( h_t \)</li>
<li>K key and Q query &lt;-&gt; \( h_s \)</li>
<li>V Value &lt;-&gt; \( p_t \)</li>
</ul>
</li>
<li>
<p>What is self-attention vs cross-attention?</p>
<ul>
<li>Self-attention is just attention to this block</li>
<li>cross-attention is query is transformed output word embedding</li>
<li>key, value is trnasformed input word embedding</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/TLSIsP1.png" alt="" /></p>
<p><img src="https://i.imgur.com/Tcu7NnR.png" alt="" /></p>
<h1><a class="header" href="#section-6-transformers-and-pretraining-in-nlp" id="section-6-transformers-and-pretraining-in-nlp">Section 6: Transformers and Pretraining in NLP</a></h1>
<h2><a class="header" href="#transformers-1" id="transformers-1">Transformers</a></h2>
<ul>
<li>
<p>What are the parts of a transformer?</p>
<ul>
<li>word embeddings</li>
<li>positional embeddings</li>
<li>self-attention</li>
<li>cross-attention</li>
<li>feed-forward layers</li>
</ul>
</li>
<li>
<p>What inputs does a transformer receive</p>
<ul>
<li>two sequences x_source and x_target</li>
</ul>
</li>
<li>
<p>What types of transformers are there?</p>
<ul>
<li>encoder attention (non-casual self-attention)</li>
<li>decoder attention (casual self-attention)</li>
<li>encoder-decoder attention (cross-attention)</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/mlNcLcg.png" alt="" /></p>
<h2><a class="header" href="#transformer-encoder-1" id="transformer-encoder-1">Transformer Encoder</a></h2>
<ul>
<li>Input + Positional Embedding</li>
<li>we use positional encoding to differential sequence positioning</li>
<li>What is the attention update function?</li>
</ul>
<p><img src="https://i.imgur.com/FQnyA88.png" alt="" /></p>
<ul>
<li>What is multihead?
<ul>
<li>has another tensor dimension!</li>
<li>\( B \times L_{source} \times D \)</li>
<li>to \( B \times H \times L_{source} \times D/H \)</li>
<li>add negative infinity for padded positions?</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#feedforward-layer" id="feedforward-layer">Feedforward layer</a></h2>
<ul>
<li>What is a feed forward layer?
<ul>
<li>literally a linear transformation (linear layer)</li>
</ul>
</li>
<li>Where is most of the computation?
<ul>
<li>in the feed forward layer!</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#transformer-decoder" id="transformer-decoder">Transformer Decoder</a></h2>
<h3><a class="header" href="#masked-decoder-self-attention" id="masked-decoder-self-attention">Masked Decoder Self-Attention</a></h3>
<ul>
<li>What is masked decoder self-attention?
<ul>
<li>We want each position in the sequence to pay attention to previous positions but not future positions.</li>
</ul>
</li>
<li>how do we do that?
<ul>
<li>if i &lt;= j set the score to q_i^T * k_j / sqrt(D) else -inf</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#encoder-decoder-attention" id="encoder-decoder-attention">Encoder-Decoder Attention</a></h2>
<ul>
<li>Aka cross-attention</li>
<li>What is the difference to other attentions?
<ul>
<li>one attention generates queries (from X_target)</li>
<li>one attention generates keys and values (from X_source)
<ul>
<li>K = X_source * W_K</li>
<li>V = X_source * W_V</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#pre-training-in-nlp" id="pre-training-in-nlp">Pre-training in NLP</a></h2>
<ul>
<li>what is the generic pre-training task?
<ul>
<li>given large <strong>unlabeled</strong> text, predict next word or predict missing word</li>
</ul>
</li>
<li>What are the two main models?
<ul>
<li>BERT (Bidirection Masked-Language Modeling)</li>
<li>GPT-2 (left to right)</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#" id=""></a></h3>
<p><img src="https://i.imgur.com/Bs1c6Xo.png" alt="" /></p>
<ul>
<li>4 different &quot;adapted&quot; tasks</li>
</ul>
<h3><a class="header" href="#gpt-2" id="gpt-2">GPT-2</a></h3>
<ul>
<li>predicts next word</li>
<li>can generate words!</li>
</ul>
<h1><a class="header" href="#section-7-fooling-networks-and-generative-models" id="section-7-fooling-networks-and-generative-models">Section 7: Fooling Networks and Generative Models</a></h1>
<h2><a class="header" href="#deep-generative-model" id="deep-generative-model">Deep Generative Model</a></h2>
<ul>
<li>What is a deep generative model?
<ul>
<li>They represent the <strong>full joint distribution</strong> \( p(x, y) \) where \( x \) is an input sample and \( y \) is an output or label</li>
<li>Review: <code>what is x (input sample)</code>?</li>
</ul>
</li>
<li>What types of deep generative models are there?
<ul>
<li>PixelRNN/PixelCNN (autogrgressive models), Variational Autoencoders (VAEe) and Generative Adversarial Networks (GANs)</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#autoregressive-models-1" id="autoregressive-models-1">Autoregressive Models</a></h2>
<ul>
<li>What is an <strong>autoregressive model</strong>?
<ul>
<li>a model that generates an image one pixel at a time</li>
<li>The probability of an image \( x\) is $$ p(x)=p(x_1,...,x_{n^2})=\prod_{i=1}^{n^2}p(x_i | x_1, ..., x_{i - 1}) $$ 
<ul>
<li>joint probability of all pixels, each pixel is the conditional probability of all past pixels</li>
</ul>
</li>
<li>We model \( p(x_i | x_1, ..., x_{i - 1}) \) with a neural network \( f_\theta \)</li>
<li>Review: <code>how do we train f_theta</code></li>
</ul>
</li>
<li>What is PixelCNN?
<ul>
<li>Uses a CNN to model the probability of a pixel given previous pixels.</li>
</ul>
</li>
<li>What are tradeoffs of PixelCNN?
<ul>
<li>It is slow at generating images. It has to go through each pixel, single pass through the image.</li>
<li>It is fast to train. It only has to go through a single pass through the image</li>
<li>Review: <code>PixelCNN</code></li>
</ul>
</li>
<li>What is PixelRNN?
<ul>
<li>Uses a RNN (LSTM) to model the probability of a pixel given previous pixels</li>
<li>Remembers distant pixels</li>
</ul>
</li>
<li>Tradeoffs of PixelRNN?
<ul>
<li>It is fast at generating images, can generate full rows in parallel</li>
<li>It is slow at training, each row has a hidden state (?)</li>
<li>Review: <code>PixelRNN</code></li>
</ul>
</li>
<li>What are the labels?
<ul>
<li>The image of a class is given. Try to predict the next pixel</li>
</ul>
</li>
<li>What is a Image Transformer?
<ul>
<li>Like PixelCNN but uses a <strong>multi-headed attention network</strong></li>
</ul>
</li>
</ul>
<h2><a class="header" href="#variational-autoencoders" id="variational-autoencoders">Variational Autoencoders</a></h2>
<ul>
<li>What is an <strong>autoencoder</strong>?
<ul>
<li>It's a model given data \( x \), predict \( x \) while compressing it into a smaller hidden state \( z \)</li>
</ul>
</li>
<li>What is an <strong>encoder</strong>?
<ul>
<li>An encoder takes a high-dimensional input \( x \) and outputs parameters of a Gaussian distribution (mean and variance \( \mu_{z|x} \) and \( \Sigma_{z|x} \)) that specify hidden variable \( z \).</li>
<li>We can model this with a deep neural network \( q_\phi(z|x) \)</li>
</ul>
</li>
<li>What is a <strong>decoder</strong>?
<ul>
<li>The decoder outputs a gaussian \( \mu_{x|z} \) and \( \Sigma_{x|z} \)) which we sample from to get \( \hat{x} \)</li>
<li>We can model this with a deep neural network \( p_\theta(x|z) \)</li>
</ul>
</li>
<li>How does a VAE generate images?
<ul>
<li>It samples latent variable \( z \) then samples \( \hat{x} \) from \( z \)</li>
</ul>
</li>
<li>How do you train a VAE?
<ul>
<li>Find parameters that maximize the likelihood of the data</li>
<li>This is intractable because of \( z \)</li>
</ul>
</li>
</ul>
<p>$$ p_\theta(x)=p_\theta(x_1,...,x_{n^2})=\int p_\theta(z)p_\theta(x|z)dz $$</p>
<p><img src="https://i.imgur.com/o5MOlGZ.png" alt="" /></p>
<ul>
<li>What is the <strong>reparameterization trick</strong>?
<ul>
<li>(?) look at lecture 17 slides</li>
<li>lots of complicated math</li>
<li>Review <code>VAE</code></li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/N96QvIi.png" alt="" /></p>
<p><img src="https://i.imgur.com/llP1nTk.png" alt="" /></p>
<ul>
<li>How do you sample from the Expectation?</li>
<li>Jensen's Inequailty</li>
</ul>
<p><img src="https://i.imgur.com/VdhyTvM.png" alt="" /></p>
<ul>
<li>Just solve this instead</li>
</ul>
<h2><a class="header" href="#generative-adversarial-networks-1" id="generative-adversarial-networks-1">Generative Adversarial Networks</a></h2>
<ul>
<li>What is the difference between a GAN and a Autoregressive Model or a VAE 
<ul>
<li>Autoregressive Models model an explicit tractable density</li>
<li>VAE model an explicit intractable density</li>
<li>GANs don't model a density. They model it implicity in a two-player game with a generator and discriminator (what the heck?)</li>
<li>Review: <code>GAN</code></li>
</ul>
</li>
<li>What is a <strong>generator</strong>?
<ul>
<li>\( G \) tries to generate real looking images \( x \) of input class given noise \( z \) (Gaussian or uniform distribution)</li>
</ul>
</li>
<li>What is a <strong>discriminator</strong>?
<ul>
<li>D tries to classify fake images.</li>
</ul>
</li>
<li>What is the GAN game?
<ul>
<li>\( \theta_G \) and \( \theta_D \) are parameters</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/6LuVsQs.png" alt="" /></p>
<ul>
<li>What is a trick used for better gradient signals?
<ul>
<li>instead of minimizing, maximize below. the gradients are more stable</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/0nOvDQp.png" alt="" /></p>
<h2><a class="header" href="#other-questions" id="other-questions">Other Questions</a></h2>
<ul>
<li>What is KL Divergence? $$ D_{KL}(p||q)=\sum_{i=1}^N p(x_i) \log(\frac{p(x_i)}{q(x_i)}) $$
<ul>
<li>\( q(x) \) approximates \( p(x) \). If they match divergence is zero, but can go up to infinity</li>
</ul>
</li>
</ul>
<h1><a class="header" href="#section-8-fairness-mdp-imitation-learning" id="section-8-fairness-mdp-imitation-learning">Section 8: Fairness, MDP, Imitation Learning</a></h1>
<h2><a class="header" href="#fairness" id="fairness">Fairness</a></h2>
<ul>
<li>We don't the model to bias irrelevant features including those legally protected
<ul>
<li>race, sex, citizenship</li>
</ul>
</li>
<li>biases:
<ul>
<li>learning algorithms rely on data</li>
<li>bias from data collection and selection</li>
<li>if bias is 0, variance is infinity</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#notation" id="notation">Notation:</a></h3>
<ul>
<li>\( X \): vector of the features of an individual</li>
<li>\( A \): the protected attributes such as national origin</li>
<li>\( Y \): label such as received loan or not</li>
<li>\( \hat{Y} = f(X, A) \): model output</li>
</ul>
<h3><a class="header" href="#definitions" id="definitions">Definitions:</a></h3>
<ul>
<li><code>Unawareness</code>: \(f(X, A) = f(X) \) a model without A does the same as a model with A
<ul>
<li>however features are usually correlated, so A camn be predicted by other attributes in X</li>
</ul>
</li>
<li><code>Demographic Parity</code>: \( P[\hat{Y} = 1 | A = 0] = P[\hat{Y} = 1 | A = 1] \) or \( \hat{Y}  ~ \bot ~ A \) (the predicted Y is <strong>conditionally independent</strong> of A).
<ul>
<li>since we have A, this solves the feature correlation problem</li>
<li>problem of <strong>Laziness</strong>, accept qualified candidate for \( A = 0 \) and randomly accept for \( A = 1 \) (with the same probability?), demographic parity is maintained</li>
</ul>
</li>
<li><code>Separation</code>: \( \hat{Y} ~ \bot ~ A | Y \) given that the candidate is qualified, the predicted Y output is independent of protected attributed.
<ul>
<li>equal opportunity</li>
<li>?</li>
</ul>
</li>
<li>What is <code>Sufficiency</code>?
<ul>
<li>\( Y ~ \bot ~ A | \hat{Y} \) given the predictors output, it should reflect the true score?</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#optimizing-for-fairness" id="optimizing-for-fairness">Optimizing for Fairness</a></h3>
<ul>
<li>How do you optimize for fairness?
<ul>
<li>minimize Jenson-Shannon divergence optimizing like a GAN</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/A57FfFX.png" alt="" /></p>
<ul>
<li>How does this work again?</li>
</ul>
<h2><a class="header" href="#markov-decision-processes-mdp" id="markov-decision-processes-mdp">Markov Decision Processes (MDP)</a></h2>
<ul>
<li>
<p>What is a <code>Markov Decision Process</code>?</p>
<ul>
<li>for games, where you have states, actions, and rewards</li>
<li>at every time step we are in state s. the agent must choose an action a for that state. Then we transition to a new state s' based on some probability distribution. On transition a reward r is generated.</li>
</ul>
</li>
<li>
<p>What is a <code>trajectory</code>?</p>
<ul>
<li>sequence of transitions</li>
<li>\( \tau = ((s_0, a_0), (s_1, a_1), ..., (s_t, a_t, r_t))</li>
</ul>
</li>
<li>
<p>How can you mathematically define a MDP?</p>
<ul>
<li>A 4-tuple: \( (S, A, T, r) \)
<ul>
<li>\( S \): set, set of states</li>
<li>\( A \): set, set of actions A[s] given state, these are the actions you can take</li>
<li>\( T(s, a) \): function(S, A) -&gt; S, transition function that takes current state adn action that returns a new state. In a <strong>stochastic MDP</strong> the new state is returned from some distribution \( P(s_new | s_old, a) \) prob of each new state given old state and action taken</li>
<li>\( r(s, a, s') \): function(S, A, S) -&gt; real, reward function for the state you are in, action you took, and state you will be in. This can also be r(s, a) where s is actually the new state s'. It's confusing sorry.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>What is <code>policy</code>?</p>
<ul>
<li>Our attempt at a solution to the MDP.</li>
<li>\( \pi(\tau) \)</li>
<li>it attempts to maximized expected reward for it's given state and action</li>
</ul>
</li>
</ul>
<p><img src="https://i.imgur.com/EogyJKY.png" alt="" /></p>
<ul>
<li>
<p>trajectory generated by the policy</p>
</li>
<li>
<p>How would you explain it if the environment was fully deterministic?</p>
<ul>
<li>you know what action to take, the one that maximizes reward</li>
</ul>
</li>
<li>
<p>What is \( \tau ~ p_{\pi}(\tau) \)?</p>
<ul>
<li>weighed sum and and prob of starting at that given state</li>
</ul>
</li>
<li>
<p>What is the <code>discount factor</code>?</p>
</li>
</ul>
<p><img src="https://i.imgur.com/jNVeL9M.png" alt="" /></p>
<ul>
<li>rewards in the present are worth more.</li>
</ul>
<h3><a class="header" href="#other-questions-1" id="other-questions-1">Other questions</a></h3>
<ul>
<li>What is Jenson-Shannon Divergence?</li>
<li>Why is \( r_t \) in the trajectory?</li>
<li>What is an example run of argmaxing the policy?</li>
</ul>
<h1><a class="header" href="#final-project-model-distillation-low-precision-neural-networks" id="final-project-model-distillation-low-precision-neural-networks">Final Project: Model Distillation Low Precision Neural Networks</a></h1>
<h1><a class="header" href="#xnor-net" id="xnor-net">XNOR-net</a></h1>
<p><a href="https://github.com/jiecaoyu/XNOR-Net-PyTorch">Repo Link</a></p>
<h2><a class="header" href="#alexnet" id="alexnet">AlexNet</a></h2>
<pre><code class="language-python">import torch
import os
import torch.nn as nn
import torch.utils.model_zoo as model_zoo
import torch.nn.functional as F

__all__ = ['AlexNet', 'alexnet']


# @Brian Binary Activation
class BinActive(torch.autograd.Function):
    '''
    Binarize the input activations and calculate the mean across channel dimension.
    '''
    def forward(self, input):
        # @Brian save input for backwards
        self.save_for_backward(input)
        size = input.size()
        # @Brian return sign of input in binary activation
        input = input.sign()
        return input

    def backward(self, grad_output):
        # @Brian throw away something?
        input, = self.saved_tensors
        grad_input = grad_output.clone()
        # @Brian if greater or equal than 1, set to 0, if less or equal to -1 set to 0?
        grad_input[input.ge(1)] = 0
        grad_input[input.le(-1)] = 0
        return grad_input

class BinConv2d(nn.Module): # change the name of BinConv2d
    def __init__(self, input_channels, output_channels,
            kernel_size=-1, stride=-1, padding=-1, groups=1, dropout=0,
            Linear=False):
        super(BinConv2d, self).__init__()
        self.layer_type = 'BinConv2d'
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        self.dropout_ratio = dropout

        # @Brian adds a dropout layer
        if dropout!=0:
            self.dropout = nn.Dropout(dropout)
        # @Brian what is linear
        self.Linear = Linear
        if not self.Linear:
            self.bn = nn.BatchNorm2d(input_channels, eps=1e-4, momentum=0.1, affine=True)
            # @Brian this layer does a convolution
            self.conv = nn.Conv2d(input_channels, output_channels,
                    kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)
        else:
            self.bn = nn.BatchNorm1d(input_channels, eps=1e-4, momentum=0.1, affine=True)
            # @Brian this layer does a linear
            self.linear = nn.Linear(input_channels, output_channels)
        self.relu = nn.ReLU(inplace=True)
    
    def forward(self, x):
        x = self.bn(x)
        # @Brian Creates Binary Activate Class
        x = BinActive()(x)
        if self.dropout_ratio!=0:
            x = self.dropout(x)
        if not self.Linear:
            x = self.conv(x)
        else:
            x = self.linear(x)
        # @Brian ReLU at the end
        x = self.relu(x)
        return x

class AlexNet(nn.Module):

    def __init__(self, num_classes=1000):
        super(AlexNet, self).__init__()
        self.num_classes = num_classes
        self.features = nn.Sequential(
            # @Brian Convolution at the front
            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),
            nn.BatchNorm2d(96, eps=1e-4, momentum=0.1, affine=True),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            # @Brian Binary Convolutions
            BinConv2d(96, 256, kernel_size=5, stride=1, padding=2, groups=1),
            nn.MaxPool2d(kernel_size=3, stride=2),
            BinConv2d(256, 384, kernel_size=3, stride=1, padding=1),
            BinConv2d(384, 384, kernel_size=3, stride=1, padding=1, groups=1),
            BinConv2d(384, 256, kernel_size=3, stride=1, padding=1, groups=1),
            nn.MaxPool2d(kernel_size=3, stride=2),
        )
        self.classifier = nn.Sequential(
            # @Brian Binary Convolutions with Linear
            BinConv2d(256 * 6 * 6, 4096, Linear=True),
            BinConv2d(4096, 4096, dropout=0.5, Linear=True),
            nn.BatchNorm1d(4096, eps=1e-3, momentum=0.1, affine=True),
            nn.Dropout(),
            # @Brian Full Linear 
            nn.Linear(4096, num_classes),
        )

    def forward(self, x):
        x = self.features(x)
        # @Brian squishes it into one vector
        x = x.view(x.size(0), 256 * 6 * 6)
        x = self.classifier(x)
        return x


def alexnet(pretrained=False, **kwargs):
    r&quot;&quot;&quot;AlexNet model architecture from the
    `&quot;One weird trick...&quot; &lt;https://arxiv.org/abs/1404.5997&gt;`_ paper.

    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
    &quot;&quot;&quot;
    model = AlexNet(**kwargs)
    if pretrained:
        model_path = 'model_list/alexnet.pth.tar'
        pretrained_model = torch.load(model_path)
        model.load_state_dict(pretrained_model['state_dict'])
    return model
</code></pre>
<h2><a class="header" href="#main-to-train-on-imagenet" id="main-to-train-on-imagenet">Main to train on ImageNet</a></h2>
<p><code>main.py</code>:</p>
<pre><code class="language-python">import argparse
import os
import shutil
import time

import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.distributed as dist
import torch.optim
import torch.utils.data
import torch.utils.data.distributed
# import torchvision.transforms as transforms
# import torchvision.datasets as datasets
import model_list
import util

# set the seed
torch.manual_seed(1)
torch.cuda.manual_seed(1)

import sys
import gc #@Brian what is this

parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')
parser.add_argument('--arch', '-a', metavar='ARCH', default='alexnet',
                    help='model architecture (default: alexnet)')
parser.add_argument('--data', metavar='DATA_PATH', default='./data/',
                    help='path to imagenet data (default: ./data/)')
parser.add_argument('--caffe-data',  default=False, action='store_true',
                    help='whether use caffe-data')
parser.add_argument('-j', '--workers', default=8, type=int, metavar='N',
                    help='number of data loading workers (default: 8)')
parser.add_argument('--epochs', default=100, type=int, metavar='N',
                    help='number of total epochs to run')
parser.add_argument('--start-epoch', default=0, type=int, metavar='N',
                    help='manual epoch number (useful on restarts)')
parser.add_argument('-b', '--batch-size', default=256, type=int,
                    metavar='N', help='mini-batch size (default: 256)')
parser.add_argument('--lr', '--learning-rate', default=0.001, type=float,
                    metavar='LR', help='initial learning rate')
parser.add_argument('--momentum', default=0.90, type=float, metavar='M',
                    help='momentum')
parser.add_argument('--weight-decay', '--wd', default=1e-5, type=float,
                    metavar='W', help='weight decay (default: 1e-5)')
parser.add_argument('--print-freq', '-p', default=10, type=int,
                    metavar='N', help='print frequency (default: 10)')
parser.add_argument('--resume', default='', type=str, metavar='PATH',
                    help='path to latest checkpoint (default: none)')
parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',
                    help='evaluate model on validation set')
parser.add_argument('--pretrained', dest='pretrained', action='store_true',
                    default=False, help='use pre-trained model')
parser.add_argument('--world-size', default=1, type=int,
                    help='number of distributed processes')
parser.add_argument('--dist-url', default='tcp://224.66.41.62:23456', type=str,
                    help='url used to set up distributed training')
parser.add_argument('--dist-backend', default='gloo', type=str,
                    help='distributed backend')

best_prec1 = 0

# define global bin_op
bin_op = None

def main():
    global args, best_prec1
    args = parser.parse_args()

    # create model
    if args.arch=='alexnet':
        model = model_list.alexnet(pretrained=args.pretrained) # @Brian get AlexNet
        input_size = 227
    else:
        raise Exception('Model not supported yet')

    if args.arch.startswith('alexnet') or args.arch.startswith('vgg'):
        # @Brian only data parallel the features?
        model.features = torch.nn.DataParallel(model.features)
        model.cuda()
    else:
        model = torch.nn.DataParallel(model).cuda()

    # define loss function (criterion) and optimizer
    criterion = nn.CrossEntropyLoss().cuda()

    optimizer = torch.optim.Adam(model.parameters(), args.lr,
                                weight_decay=args.weight_decay)

    for m in model.modules():
        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
            c = float(m.weight.data[0].nelement()) # @Brian initial weights of layer
            m.weight.data = m.weight.data.normal_(0, 2.0/c)
        elif isinstance(m, nn.BatchNorm2d):
            m.weight.data = m.weight.data.zero_().add(1.0) # @Brian initial weight batch norm
            m.bias.data = m.bias.data.zero_()

    # optionally resume from a checkpoint
    if args.resume:
        if os.path.isfile(args.resume):
            print(&quot;=&gt; loading checkpoint '{}'&quot;.format(args.resume))
            checkpoint = torch.load(args.resume)
            args.start_epoch = checkpoint['epoch']
            best_prec1 = checkpoint['best_prec1']
            model.load_state_dict(checkpoint['state_dict'])
            optimizer.load_state_dict(checkpoint['optimizer'])
            print(&quot;=&gt; loaded checkpoint '{}' (epoch {})&quot;
                  .format(args.resume, checkpoint['epoch']))
            del checkpoint
        else:
            print(&quot;=&gt; no checkpoint found at '{}'&quot;.format(args.resume))

    cudnn.benchmark = True

    # Data loading code

    if args.caffe_data:
        print('==&gt; Using Caffe Dataset')
        cwd = os.getcwd()
        sys.path.append(cwd+'/../')
        import datasets as datasets
        import datasets.transforms as transforms
        if not os.path.exists(args.data+'/imagenet_mean.binaryproto'):
            print(&quot;==&gt; Data directory&quot;+args.data+&quot;does not exits&quot;)
            print(&quot;==&gt; Please specify the correct data path by&quot;)
            print(&quot;==&gt;     --data &lt;DATA_PATH&gt;&quot;)
            return

        normalize = transforms.Normalize(
                meanfile=args.data+'/imagenet_mean.binaryproto')


        train_dataset = datasets.ImageFolder(
            args.data,
            transforms.Compose([
                transforms.RandomHorizontalFlip(),
                transforms.ToTensor(),
                normalize,
                transforms.RandomSizedCrop(input_size),
            ]),
            Train=True)

        train_sampler = None

        train_loader = torch.utils.data.DataLoader(
            train_dataset, batch_size=args.batch_size, shuffle=False,
            num_workers=args.workers, pin_memory=True, sampler=train_sampler)

        val_loader = torch.utils.data.DataLoader(
            datasets.ImageFolder(args.data, transforms.Compose([
                transforms.ToTensor(),
                normalize,
                transforms.CenterCrop(input_size),
            ]),
            Train=False),
            batch_size=args.batch_size, shuffle=False,
            num_workers=args.workers, pin_memory=True)
    else:
        print('==&gt; Using Pytorch Dataset')
        import torchvision
        import torchvision.transforms as transforms
        import torchvision.datasets as datasets
        traindir = os.path.join(args.data, 'train')
        valdir = os.path.join(args.data, 'val')
        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                std=[1./255., 1./255., 1./255.])

        torchvision.set_image_backend('accimage')

        train_dataset = datasets.ImageFolder(
                traindir,
                transforms.Compose([
                    transforms.Resize((256, 256)),
                    transforms.RandomCrop(input_size),
                    transforms.RandomHorizontalFlip(),
                    transforms.ToTensor(),
                    normalize,
                    ]))

        train_loader = torch.utils.data.DataLoader(
                train_dataset, batch_size=args.batch_size, shuffle=True,
                num_workers=args.workers, pin_memory=True)
        val_loader = torch.utils.data.DataLoader(
                datasets.ImageFolder(valdir, transforms.Compose([
                    transforms.Resize((256, 256)),
                    transforms.CenterCrop(input_size),
                    transforms.ToTensor(),
                    normalize,
                    ])),
                batch_size=args.batch_size, shuffle=False,
                num_workers=args.workers, pin_memory=True)

    print model

    # define the binarization operator
    global bin_op
    bin_op = util.BinOp(model) # @Brian Binarization @TODO look at this

    if args.evaluate:
        validate(val_loader, model, criterion)
        return

    for epoch in range(args.start_epoch, args.epochs):
        adjust_learning_rate(optimizer, epoch)

        # train for one epoch
        train(train_loader, model, criterion, optimizer, epoch)

        # evaluate on validation set
        prec1 = validate(val_loader, model, criterion)

        # remember best prec@1 and save checkpoint
        is_best = prec1 &gt; best_prec1
        best_prec1 = max(prec1, best_prec1)
        save_checkpoint({
            'epoch': epoch + 1,
            'arch': args.arch,
            'state_dict': model.state_dict(),
            'best_prec1': best_prec1,
            'optimizer' : optimizer.state_dict(),
        }, is_best)


def train(train_loader, model, criterion, optimizer, epoch):
    batch_time = AverageMeter()
    data_time = AverageMeter()
    losses = AverageMeter()
    top1 = AverageMeter()
    top5 = AverageMeter()

    # switch to train mode
    model.train()

    end = time.time()
    for i, (input, target) in enumerate(train_loader):
        # measure data loading time
        data_time.update(time.time() - end)

        target = target.cuda(async=True)
        input_var = torch.autograd.Variable(input)
        target_var = torch.autograd.Variable(target)

        # process the weights including binarization
        bin_op.binarization() # @Brian global, binarization
        
        # compute output
        output = model(input_var)
        loss = criterion(output, target_var)

        # measure accuracy and record loss
        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))
        losses.update(loss.data.item(), input.size(0)) # @Brian the type is AverageMeter what is a AverageMeter
        top1.update(prec1[0], input.size(0))
        top5.update(prec5[0], input.size(0))

        # compute gradient and do SGD step
        optimizer.zero_grad()
        loss.backward() # @Brian computes full precision gradient

        # restore weights
        bin_op.restore() # @Brian does it requantize it?
        bin_op.updateBinaryGradWeight()

        optimizer.step()

        # measure elapsed time
        batch_time.update(time.time() - end)
        end = time.time()

        if i % args.print_freq == 0:
            print('Epoch: [{0}][{1}/{2}]\t'
                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\t'
                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\t'
                  'Loss {loss.val:.4f} ({loss.avg:.4f})\t'
                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\t'
                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(
                   epoch, i, len(train_loader), batch_time=batch_time,
                   data_time=data_time, loss=losses, top1=top1, top5=top5))
        gc.collect()


def validate(val_loader, model, criterion):
    batch_time = AverageMeter()
    losses = AverageMeter()
    top1 = AverageMeter()
    top5 = AverageMeter()

    # switch to evaluate mode
    model.eval()

    end = time.time()
    bin_op.binarization() # @Brian what does this do?
    for i, (input, target) in enumerate(val_loader):
        target = target.cuda(async=True)
        with torch.no_grad():
            input_var = torch.autograd.Variable(input)
            target_var = torch.autograd.Variable(target)

        # compute output
        output = model(input_var)
        loss = criterion(output, target_var)

        # measure accuracy and record loss
        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))
        losses.update(loss.data.item(), input.size(0))
        top1.update(prec1[0], input.size(0))
        top5.update(prec5[0], input.size(0))

        # measure elapsed time
        batch_time.update(time.time() - end)
        end = time.time()

        if i % args.print_freq == 0:
            print('Test: [{0}/{1}]\t'
                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\t'
                  'Loss {loss.val:.4f} ({loss.avg:.4f})\t'
                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\t'
                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(
                   i, len(val_loader), batch_time=batch_time, loss=losses,
                   top1=top1, top5=top5))
    bin_op.restore()

    print(' * Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'
          .format(top1=top1, top5=top5))

    return top1.avg


def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):
    torch.save(state, filename)
    if is_best:
        shutil.copyfile(filename, 'model_best.pth.tar')


class AverageMeter(object):
    &quot;&quot;&quot;Computes and stores the average and current value&quot;&quot;&quot;
    def __init__(self):
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count # @Brian basically gets a validation


def adjust_learning_rate(optimizer, epoch):
    &quot;&quot;&quot;Sets the learning rate to the initial LR decayed by 10 every 30 epochs&quot;&quot;&quot;
    lr = args.lr * (0.1 ** (epoch // 30))
    print 'Learning rate:', lr
    for param_group in optimizer.param_groups:
        param_group['lr'] = lr


def accuracy(output, target, topk=(1,)):
    &quot;&quot;&quot;Computes the precision@k for the specified values of k&quot;&quot;&quot;
    maxk = max(topk)
    batch_size = target.size(0)

    _, pred = output.topk(maxk, 1, True, True)
    pred = pred.t()
    correct = pred.eq(target.view(1, -1).expand_as(pred))

    res = []
    for k in topk:
        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)
        res.append(correct_k.mul_(100.0 / batch_size))
    return res


if __name__ == '__main__':
    main()
</code></pre>
<h2><a class="header" href="#utils" id="utils">Utils</a></h2>
<pre><code class="language-python">import torch.nn as nn
import numpy

class BinOp():
    def __init__(self, model): # @Brian takes in a model
        # count the number of Conv2d and Linear
        count_targets = 0
        for m in model.modules():
            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
                count_targets = count_targets + 1

        start_range = 1
        end_range = count_targets-2
        self.bin_range = numpy.linspace(start_range,
                end_range, end_range-start_range+1)\
                        .astype('int').tolist()
        self.num_of_params = len(self.bin_range)
        self.saved_params = []
        self.target_params = []
        self.target_modules = []
        index = -1
        for m in model.modules():
            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
                index = index + 1
                if index in self.bin_range:
                    tmp = m.weight.data.clone()
                    self.saved_params.append(tmp)
                    self.target_modules.append(m.weight)

    def binarization(self):
        self.meancenterConvParams() # @Brian what is binarization
        self.clampConvParams()
        self.save_params()
        self.binarizeConvParams()

    def meancenterConvParams(self):
        for index in range(self.num_of_params):
            s = self.target_modules[index].data.size()
            negMean = self.target_modules[index].data.mean(1, keepdim=True).\
                    mul(-1).expand_as(self.target_modules[index].data) # @Brian what is mul(-1) and expand_as
            self.target_modules[index].data = self.target_modules[index].data.add(negMean)

    def clampConvParams(self):
        for index in range(self.num_of_params):
            self.target_modules[index].data = \
                    self.target_modules[index].data.clamp(-1.0, 1.0) # @Brian clamp

    def save_params(self):
        for index in range(self.num_of_params):
            self.saved_params[index].copy_(self.target_modules[index].data) # @Brian then saves the params

    def binarizeConvParams(self):
        for index in range(self.num_of_params):
            n = self.target_modules[index].data[0].nelement()
            s = self.target_modules[index].data.size()
            if len(s) == 4:
                m = self.target_modules[index].data.norm(1, 3, keepdim=True)\
                        .sum(2, keepdim=True).sum(1, keepdim=True).div(n) # @Brian normalizes it
            elif len(s) == 2:
                m = self.target_modules[index].data.norm(1, 1, keepdim=True).div(n) # @Brian ?
            self.target_modules[index].data = \
                    self.target_modules[index].data.sign().mul(m.expand(s)) # @Brian ?

    def restore(self):
        for index in range(self.num_of_params):
            self.target_modules[index].data.copy_(self.saved_params[index]) # @Brian resets from the saved params

    def updateBinaryGradWeight(self):
        for index in range(self.num_of_params):
            weight = self.target_modules[index].data
            n = weight[0].nelement()
            s = weight.size()
            if len(s) == 4:
                m = weight.norm(1, 3, keepdim=True)\
                        .sum(2, keepdim=True).sum(1, keepdim=True).div(n).expand(s) # @Brian what is this?
            elif len(s) == 2:
                m = weight.norm(1, 1, keepdim=True).div(n).expand(s)
            m[weight.lt(-1.0)] = 0 
            m[weight.gt(1.0)] = 0
            m = m.mul(self.target_modules[index].grad.data)
            m_add = weight.sign().mul(self.target_modules[index].grad.data)
            if len(s) == 4:
                m_add = m_add.sum(3, keepdim=True)\
                        .sum(2, keepdim=True).sum(1, keepdim=True).div(n).expand(s)
            elif len(s) == 2:
                m_add = m_add.sum(1, keepdim=True).div(n).expand(s)
            m_add = m_add.mul(weight.sign())
            self.target_modules[index].grad.data = m.add(m_add).mul(1.0-1.0/s[1]).mul(n)
            self.target_modules[index].grad.data = self.target_modules[index].grad.data.mul(1e+9) # @Brian this does not make sense 

# @Brian what are expand, sum, norm, div, expand_as used for?
</code></pre>
<h1><a class="header" href="#knowledge-distillation" id="knowledge-distillation">Knowledge Distillation</a></h1>
<ul>
<li><a href="https://www.cs.toronto.edu/%7Ehinton/absps/distillation.pdf">Link</a></li>
</ul>
<h1><a class="header" href="#dorefa-net" id="dorefa-net">DoReFa-Net</a></h1>
<h2><a class="header" href="#abstract" id="abstract">Abstract</a></h2>
<ul>
<li>low bitwidth weights and activation
<ul>
<li>1 bit weights, 2 bit activations</li>
</ul>
</li>
<li>low bitwidth gradients</li>
</ul>
<p><img src="https://i.imgur.com/isbpqr4.png" alt="" /></p>
<ul>
<li>bitcount when both weight and input activations are binarized (XNOR-net 2016).</li>
<li>1 bit convolution kernels?</li>
<li>1 bit weights, 1 bit activations and 2 bit gradients do well</li>
</ul>
<p><img src="https://i.imgur.com/isbpqr4.png" alt="" /></p>
<ul>
<li>x and y are arrays of bits, the floating point can be calculated by those sums.</li>
</ul>
<p><img src="https://i.imgur.com/UKMw0Vt.png" alt="" /></p>
<ul>
<li>dot product</li>
</ul>
<p><img src="https://i.imgur.com/aagv0oS.png" alt="" /></p>
<ul>
<li>Straight through estimator through sampling and quantization</li>
</ul>
<p><img src="https://i.imgur.com/77wxwFU.png" alt="" /></p>
<ul>
<li>k bit representation with tanh to constraint to [-1, 1]</li>
</ul>
<p><img src="https://i.imgur.com/OuygHvF.png" alt="" /></p>
<ul>
<li>.975 with all accurcay</li>
<li>.934 with 1W, 1A, 1G</li>
<li>.971 with 1W, 1A, 32G</li>
<li>W,A =(1,2) and G &gt;= 4 is best</li>
</ul>
<p>Quantizing the first and last layers leads to significant degradation </p>
<p>FPGAs with B-bit arithmetic is good at low bitwidth convolutions</p>
<h1><a class="header" href="#apprentice-knowledge-distillation-with-low-precision-networks" id="apprentice-knowledge-distillation-with-low-precision-networks">Apprentice: Knowledge Distillation with Low-Precision Networks</a></h1>
<p><a href="https://arxiv.org/pdf/1711.05852.pdf">Paper</a></p>
<h2><a class="header" href="#abstract-1" id="abstract-1">Abstract</a></h2>
<p>Low-precision numerics and model compression using knowledge distillation are popular techniques to lower both the compute requirements and memory footprint of these deployed model</p>
<p>Ternary Precision and 4-bit precision</p>
<p>Knowledge Distillation is used to &quot;transfer knowledge&quot; from the complex network to the smaller network.</p>
<h2><a class="header" href="#three-schemes" id="three-schemes">Three schemes</a></h2>
<ol>
<li>low-precision network and full-precision network</li>
<li>continuous knowledge transfer, - low-precision network trains faster</li>
<li>init with the full precision weights and gradually decrease precision</li>
</ol>
<p>Hinton does knowledge distillation by diving the logits by a temperature before softmax. A higher temperature makes incorrect classes boosted.</p>
<h2><a class="header" href="#knowledge-distillation-1" id="knowledge-distillation-1">Knowledge Distillation</a></h2>
<p><img src="https://i.imgur.com/0cezU7F.png" alt="" /></p>
<ul>
<li>\( \alpha=1, \beta=0.5, \gamma=0.5 \)</li>
</ul>
<p><img src="https://i.imgur.com/3ysbRRY.png" alt="" /></p>
<ul>
<li>
<p>The third term and the line from student to teacher is the \ student network attempts to mimic the knowledge of the teacher network.</p>
</li>
<li>
<p>We can change the params?</p>
</li>
</ul>
<p>They use ternary and 4 bit precision</p>
<p><img src="https://i.imgur.com/Ti1X2cy.png" alt="" /></p>
<ul>
<li>Oh it's error rate. Accuracy is 100% - that value</li>
</ul>
<p><img src="https://i.imgur.com/tSaBnFj.png" alt="" /></p>
<ul>
<li>Improves accuracy!</li>
</ul>
<p><img src="https://i.imgur.com/hnoA0iI.png" alt="" /></p>
<ul>
<li></li>
</ul>
<p><img src="https://i.imgur.com/hnoA0iI.png" alt="" /></p>
<ul>
<li>27.2% Top-1 error </li>
</ul>
<p><img src="https://i.imgur.com/cWYhF88.png" alt="" /></p>
<ul>
<li>32A, 2W (ternary?) and 8A, 4W</li>
</ul>
<h1><a class="header" href="#improved-knowledge-distillation-via-teacher-assistant" id="improved-knowledge-distillation-via-teacher-assistant">Improved Knowledge Distillation via Teacher Assistant</a></h1>
<ul>
<li>
<p><a href="https://arxiv.org/pdf/1902.03393.pdf">Link</a></p>
</li>
<li>
<p>However, we argue that knowledge distillation is not always effective, especially when the gap (in size) between
teacher and student is large</p>
</li>
<li>
<p>Hinton, et. al (2015) do knowledge distillation from the logit with a tempature function.</p>
<ul>
<li>The so-called dark knowledge transferred in the process helps the student learn the finer structure of teacher network. Hinton, Vinyals, and Dean (2015) argues that the success of knowledge distillation is attributed to the logit distribution of the incorrect outputs, which provides information on the similarity between output categories.</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#knowledge-distillation-2" id="knowledge-distillation-2">Knowledge Distillation</a></h2>
<p><img src="https://i.imgur.com/I3TbjGP.png" alt="" /></p>
<ul>
<li>\( a_s \) is logit (before softmax) of student, \( y_r \) is true label</li>
</ul>
<p><img src="https://i.imgur.com/prFCVW1.png" alt="" /></p>
<ul>
<li>The student tries to match student and teacher logits.
<ul>
<li>\( y_s = \text{softmax}(\frac{a_s}{\tau}) \)</li>
<li>\( y_t = \text{softmax}(\frac{a_t}{\tau}) \)</li>
</ul>
</li>
<li>KL divergence tries to match the two distributions</li>
</ul>
<p><img src="https://i.imgur.com/5mb4wyg.png" alt="" /></p>
<ul>
<li>The final loss function</li>
</ul>
<p><img src="https://i.imgur.com/SqMzJ7s.png" alt="" /></p>
<ul>
<li>Teacher accuracy increases as teacher size increases yet student size decreases</li>
<li>Solution: Use TA networks in between to smooth the transition!</li>
</ul>
<h2><a class="header" href="#what-is-the-best-ta-size" id="what-is-the-best-ta-size">What is the best TA size?</a></h2>
<p><img src="https://i.imgur.com/C6cWTkf.png" alt="" /></p>
<ul>
<li>mean the network size is good</li>
</ul>
<p><img src="https://i.imgur.com/CxjetZa.png" alt="" /></p>
<ul>
<li>Highest accuracy is most distillation steps</li>
</ul>
<h1><a class="header" href="#teacher-assistant-code" id="teacher-assistant-code">Teacher Assistant Code</a></h1>
<p><code>train.py</code></p>
<pre><code class="language-python">import os
import nni # @Brian what is this?
import copy
import torch
import argparse
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from data_loader import get_cifar
from model_factory import create_cnn_model, is_resnet # @Brian what is in model_factory?


def str2bool(v):
    if v.lower() in ('yes', 'true', 't', 'y', '1'):
        return True
    else:
        return False
    
    
def parse_arguments():
    parser = argparse.ArgumentParser(description='TA Knowledge Distillation Code')
    parser.add_argument('--epochs', default=200, type=int,  help='number of total epochs to run') # @Brian default 200
    parser.add_argument('--dataset', default='cifar100', type=str, help='dataset. can be either cifar10 or cifar100')
    parser.add_argument('--batch-size', default=128, type=int, help='batch_size')
    parser.add_argument('--learning-rate', default=0.1, type=float, help='initial learning rate')
    parser.add_argument('--momentum', default=0.9, type=float,  help='SGD momentum')
    parser.add_argument('--weight-decay', default=1e-4, type=float, help='SGD weight decay (default: 1e-4)')
    parser.add_argument('--teacher', default='', type=str, help='teacher student name') # @Brian Teacher
    parser.add_argument('--student', '--model', default='resnet8', type=str, help='teacher student name') # @Brian Student, but also a model param?
    parser.add_argument('--teacher-checkpoint', default='', type=str, help='optinal pretrained checkpoint for teacher') # @Brian teacher state 
    parser.add_argument('--cuda', default=False, type=str2bool, help='whether or not use cuda(train on GPU)')
    parser.add_argument('--dataset-dir', default='./data', type=str,  help='dataset directory')
    args = parser.parse_args()
    return args


def load_checkpoint(model, checkpoint_path):
    &quot;&quot;&quot;
    Loads weights from checkpoint
    :param model: a pytorch nn student
    :param str checkpoint_path: address/path of a file
    :return: pytorch nn student with weights loaded from checkpoint
    &quot;&quot;&quot;
    model_ckp = torch.load(checkpoint_path) # @Brian name is name is {}_{}_epoch{}.pth.tar'.format(self.name, trial_id, epoch),
    model.load_state_dict(model_ckp['model_state_dict']) # @Brian see line 135 for format
    return model


class TrainManager(object):
    def __init__(self, student, teacher=None, train_loader=None, test_loader=None, train_config={}):
        self.student = student
        self.teacher = teacher
        self.have_teacher = bool(self.teacher) # @Brian has teacher
        self.device = train_config['device']
        self.name = train_config['name']
        self.optimizer = optim.SGD(self.student.parameters(),
                                   lr=train_config['learning_rate'],
                                   momentum=train_config['momentum'],
                                   weight_decay=train_config['weight_decay'])
        if self.have_teacher:
            self.teacher.eval() # @Brian why eval?
            self.teacher.train(mode=False) # @Brian why train with false?
            
        self.train_loader = train_loader
        self.test_loader = test_loader
        self.config = train_config
    
    def train(self):
        lambda_ = self.config['lambda_student'] # @Brian what is a lambda student
        T = self.config['T_student']
        epochs = self.config['epochs']
        trial_id = self.config['trial_id']
        
        max_val_acc = 0
        iteration = 0
        best_acc = 0
        criterion = nn.CrossEntropyLoss()
        for epoch in range(epochs):
            self.student.train() # @Brian what does self.student.train() do?
            self.adjust_learning_rate(self.optimizer, epoch)
            loss = 0
            for batch_idx, (data, target) in enumerate(self.train_loader):
                iteration += 1
                data = data.to(self.device)
                target = target.to(self.device)
                self.optimizer.zero_grad()
                output = self.student(data)
                # Standard Learning Loss ( Classification Loss)
                loss_SL = criterion(output, target) # @Brian they use a criterion loss. THIS IS IMPORTANT
                loss = loss_SL
                
                if self.have_teacher: # @Brian here is the knowledge distillation
                    teacher_outputs = self.teacher(data)
                    # Knowledge Distillation Loss
                    loss_KD = nn.KLDivLoss()(F.log_softmax(output / T, dim=1),
                                                      F.softmax(teacher_outputs / T, dim=1))
                    loss = (1 - lambda_) * loss_SL + lambda_ * T * T * loss_KD
                    
                loss.backward()
                self.optimizer.step()
            
            print(&quot;epoch {}/{}&quot;.format(epoch, epochs))
            val_acc = self.validate(step=epoch)
            if val_acc &gt; best_acc: # @Brian if validation accuracy is greater than best accuracy, save that state
                best_acc = val_acc
                self.save(epoch, name='{}_{}_best.pth.tar'.format(self.name, trial_id))
        
        return best_acc
    
    def validate(self, step=0):
        self.student.eval()
        with torch.no_grad():
            correct = 0
            total = 0
            acc = 0
            for images, labels in self.test_loader:
                images = images.to(self.device)
                labels = labels.to(self.device)
                outputs = self.student(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item() # @Brian how many predicted are correctly labeled
            # self.accuracy_history.append(acc)
            acc = 100 * correct / total
            
            print('{{&quot;metric&quot;: &quot;{}_val_accuracy&quot;, &quot;value&quot;: {}}}'.format(self.name, acc))
            return acc
    
    def save(self, epoch, name=None): # @Brian save epoch, model state, and optimizer state
        trial_id = self.config['trial_id']
        if name is None:
            torch.save({
                'epoch': epoch,
                'model_state_dict': self.student.state_dict(),
                'optimizer_state_dict': self.optimizer.state_dict(),
            }, '{}_{}_epoch{}.pth.tar'.format(self.name, trial_id, epoch))
        else:
            torch.save({
                'model_state_dict': self.student.state_dict(),
                'optimizer_state_dict': self.optimizer.state_dict(),
                'epoch': epoch,
            }, name)
    
    def adjust_learning_rate(self, optimizer, epoch):
        epochs = self.config['epochs']
        models_are_plane = self.config['is_plane'] # @Brian what does this mean?
        
        # depending on dataset
        if models_are_plane:
            lr = 0.01 # @Brian basically keep the learning rate the same
        else:
            if epoch &lt; int(epoch/2.0):
                lr = 0.1
            elif epoch &lt; int(epochs*3/4.0):
                lr = 0.1 * 0.1
            else:
                lr = 0.1 * 0.01
        # @Brian lr is 0.1 &lt; epoch/2.0, then 0.01 to 3/4 * epoch then 0.001 rest.
        # update optimizer's learning rate
        for param_group in optimizer.param_groups:
            param_group['lr'] = lr


if __name__ == &quot;__main__&quot;:
    # Parsing arguments and prepare settings for training
    args = parse_arguments()
    print(args)
    config = nni.get_next_parameter() # @Brian https://pypi.org/project/nni/ neural network intelligence package
    torch.manual_seed(config['seed'])
    torch.cuda.manual_seed(config['seed'])
    trial_id = os.environ.get('NNI_TRIAL_JOB_ID')
    dataset = args.dataset
    num_classes = 100 if dataset == 'cifar100' else 'cifar10'
    teacher_model = None
    student_model = create_cnn_model(args.student, dataset, use_cuda=args.cuda) # @Brian  why not the ResNet?
    train_config = {
        'epochs': args.epochs,
        'learning_rate': args.learning_rate,
        'momentum': args.momentum,
        'weight_decay': args.weight_decay,
        'device': 'cuda' if args.cuda else 'cpu',
        'is_plane': not is_resnet(args.student),
        'trial_id': trial_id,
        'T_student': config.get('T_student'),
        'lambda_student': config.get('lambda_student'), # @Brian what is lambda student?
    }
    
    
    # Train Teacher if provided a teacher, otherwise it's a normal training using only cross entropy loss
    # This is for training single models(NOKD in paper) for baselines models (or training the first teacher)
    if args.teacher:
        teacher_model = create_cnn_model(args.teacher, dataset, use_cuda=args.cuda)
        if args.teacher_checkpoint:
            print(&quot;---------- Loading Teacher -------&quot;)
            teacher_model = load_checkpoint(teacher_model, args.teacher_checkpoint)
        else:
            print(&quot;---------- Training Teacher -------&quot;)
            train_loader, test_loader = get_cifar(num_classes)
            teacher_train_config = copy.deepcopy(train_config)
            teacher_name = '{}_{}_best.pth.tar'.format(args.teacher, trial_id)
            teacher_train_config['name'] = args.teacher
            teacher_trainer = TrainManager(teacher_model, teacher=None, train_loader=train_loader, test_loader=test_loader, train_config=teacher_train_config)
            teacher_trainer.train()
            teacher_model = load_checkpoint(teacher_model, os.path.join('./', teacher_name))
    # @Brian if have teacher load the teacher or train the teacher        
    # Student training
    print(&quot;---------- Training Student -------&quot;)
    student_train_config = copy.deepcopy(train_config)
    train_loader, test_loader = get_cifar(num_classes)
    student_train_config['name'] = args.student
    student_trainer = TrainManager(student_model, teacher=teacher_model, train_loader=train_loader, test_loader=test_loader, train_config=student_train_config)
    best_student_acc = student_trainer.train()
    nni.report_final_result(best_student_acc)

</code></pre>
<h1><a class="header" href="#exam-practice" id="exam-practice">Exam Practice</a></h1>
<h1><a class="header" href="#midterm-1" id="midterm-1">Midterm 1</a></h1>
<h1><a class="header" href="#midterm-1-spring-2019" id="midterm-1-spring-2019">Midterm 1 Spring 2019</a></h1>
<p><img src="https://i.imgur.com/0WqLprF.png" alt="" /></p>
<ol>
<li>
<p>a.</p>
<ul>
<li><strong>Ans:</strong> AlexNet is deeper. AlexNet is split on GPUs.</li>
<li><strong>Corrections:</strong> AlexNet uses ReLU, LeNet uses Sigmoid</li>
<li><strong>Review:</strong> <code>AlexNet and LeNet</code></li>
</ul>
<p>b. </p>
<ul>
<li><strong>Ans:</strong> Multi-task learning is you replace the end layers of a network including the classifier, and can connect it to other tasks like question and answering. This makes it more robust to learn representations in images.</li>
<li><strong>Corrections:</strong> Layers are shared in a network (shared representation). The network is applied to multiple tasks. Benefits are: the network has extra information to capture the essence of a task, and avoids overfitting by learning more robust features.</li>
<li><strong>Review:</strong> <code>multi-task learning</code></li>
</ul>
<p>c.</p>
<ul>
<li><strong>Ans:</strong> Generative Models try to generate the joint distribution \( P(B,A) \). Discriminative models try to model only the decision boundary.</li>
<li><strong>Corrections:</strong> generate is &quot;sample&quot; data from distribution. Can't say it models \( P(X, Y) \). Discriminative doesn't need assumptions aboutd data, can model more complex distributions.</li>
<li><strong>Review:</strong> <code>Generative vs Discriminative Models</code></li>
</ul>
</li>
</ol>
<p><img src="https://i.imgur.com/mZLgVpH.png" alt="" /></p>
<ol>
<li>
<p>d.</p>
<ul>
<li><strong>Ans:</strong> Cross Entropy is used for discrete values</li>
<li><strong>Corrections:</strong> Cross entropy loss (which is log loss in the binary case)</li>
<li><strong>Review:</strong> <code>Squared Error Loss and Cross Entropy Loss. Review Loss vs. Risk</code></li>
</ul>
<p>e.</p>
<ul>
<li><strong>Ans:</strong> (rip)</li>
<li><strong>Corrections:</strong> Loss gradients push the boundary to move points outside the margin. Close points have very large gradients.</li>
<li><strong>Review:</strong> <code>Logistic Regression, its training algorithm</code></li>
</ul>
</li>
</ol>
<p><img src="https://i.imgur.com/ZoKIsmv.png" alt="" /></p>
<ol>
<li>
<p>f.</p>
<ul>
<li><strong>Ans:</strong> Bias is how accurate the model is on learning the relationship between x and y. Variance is how accurate the model is to data it has not seen. Deep neural networks have high variance and low bias.</li>
<li><strong>Corrections:</strong> Complex models can fit data better (low bias) but are more sensitive to data (high variance) Regularization reduces variance at expense for bias. Deep neural networks are low-bias, high variance</li>
<li><strong>Review</strong>: <code>bias variance tradeoff, regularization, deep networks are low bias high variance</code></li>
</ul>
<p>g.</p>
<ul>
<li><strong>Ans:</strong> When each variable is independent. Logistic regression is more accurate when this is not the case and there is more data.</li>
<li><strong>Corrections:</strong> Naive Bayes assumes feature values are conditionally independent based on class label. Logistic regression doesn't make that assumption and is more accurate when that is not the case.</li>
<li><strong>Review</strong>: <code>Naive Bayes, Conditional Independence on class label, Logistic Regression.</code></li>
</ul>
</li>
</ol>
<p><img src="https://i.imgur.com/h77LjNU.png" alt="" /></p>
<ol>
<li>
<p>h.</p>
<ul>
<li><strong>Review:</strong> Gradients vanishes at local minima, maxima and saddle points</li>
<li><strong>Corrections:</strong></li>
<li><strong>Review:</strong> <code>Vanishing Gradients</code></li>
</ul>
<p>i.</p>
<ul>
<li><strong>Review:</strong> \( 128 \times 64 \times 64 \)</li>
<li><strong>Corrections:</strong></li>
<li><strong>Review:</strong> <code>Convolution Equation</code></li>
</ul>
<p>j.</p>
<ul>
<li><strong>Review:</strong> Split dataset into <code>k+1</code> subsets taking one out for testing. On round <code>i</code>, hold <code>i</code> for validation and and the rest of the <code>k</code> for training. Repeat with different holdout sets.</li>
<li><strong>Corrections:</strong> Check on fold <code>i</code> (validation data)</li>
<li><strong>Review:</strong> <code>Cross Validation</code></li>
</ul>
</li>
</ol>
<h1><a class="header" href="#midterm-1-practice-1-spring-2018" id="midterm-1-practice-1-spring-2018">Midterm 1 Practice 1 Spring 2018</a></h1>
<p><img src="https://i.imgur.com/v1k6bSW.png" alt="" /></p>
<ol>
<li>
<p>a. Objects can be seen from different perspectives. Lighting can be different. Objects can be blocked; object partially visible.</p>
<ul>
<li><strong>Review:</strong> <code>Lecture 1.</code></li>
</ul>
<p>b. When doing transfer learning, the network has already extracted high level like edges, mid level like shapes and lines, and low level like faces. These generalize and don't have to be updated too much in being fine tuned. <strong>The already trained low-dimensional features capture the essence of the data, can have faster fine-tuning.</strong></p>
<ul>
<li><strong>Review:</strong> <code>Lecture 1, Transfer Learning.</code></li>
</ul>
<p>c. Expected Risk is <strong>expectation</strong> over all datasets of model loss (prediction  actual result). Empirical risk is difference over a fixed dataset sample. Machine Learning minimizes empirical risk.</p>
<ul>
<li><strong>Review:</strong> <code>Expected Risk, Empirical Risk, Loss vs Risk.</code></li>
</ul>
</li>
</ol>
<p><img src="https://i.imgur.com/Z5g6JuI.png" alt="" /></p>
<ol>
<li>
<p>d. L2 is designed for loss of continuous value functions. Logistic regression is for binary classification (0 or 1). We use binary cross-entropy loss. (It encourages outputs to be 0 or 1?) The loss becomes a probability?</p>
<ul>
<li><strong>Review:</strong> <code>L2 Loss vs Cross-Entropy Loss</code></li>
<li>Why does it work for binary/discrete classification vs L2 for continuous? What is the relationship of it to probability?</li>
</ul>
<p>e. Newton's second-order method converge to local minima and saddle points. Where second derivative gradients (is this correct?) are zero</p>
<ul>
<li><strong>Review:</strong> <code>Netwon Second-Order Methods</code></li>
</ul>
<p>f. Using a max-margin classifier is the most robust (decreases overfitting) classifier to unseen data. It maximizes distance of the nearest points to the margin/decision boundary. Diagram shows decision boundary with max distance to nearest points</p>
<ul>
<li><strong>Review:</strong> <code>SVM, Max-Margin, Hinge Loss</code></li>
</ul>
</li>
</ol>
<p><img src="https://i.imgur.com/ray5suc.png" alt="" /></p>
<ol>
<li>g. for each data point \( (x_i, y_i) \), we have \( f_{y_i}(x_i) - f_j(x_i) \) (the difference) for all classes \( j \neq y \). The original SVM loss is \( max(0, 1 - yw^Tx) \). Max margins for all classes not \( j \) is \( max(0, 1 - f_{y_i}(x_i) + f_j(x_i) \). Loss is sum/averaged. OvA classifer? What the heck is this?
<ul>
<li><strong>Review:</strong> <code>SVM</code></li>
</ul>
</li>
</ol>
<p><img src="https://i.imgur.com/yCRut4F.png" alt="" /></p>
<ol>
<li>
<p>h. Multiclass logistic regression can learn the multiclass naive Bayes</p>
<ul>
<li><strong>Review:</strong> <code>Multiclass Logistic Regression, Multiclass Naive Bayes, their relationship</code></li>
</ul>
<p>i. Gradient decreases proportionally to accumulating value at \( \approx \frac{1}{\sqrt{t}}\). This is because the denominator of the update contains sum of squares of past gradients.</p>
</li>
</ol>
<p><img src="https://i.imgur.com/0rGE4yp.png" alt="" /></p>
<ol>
<li>
<p>j. </p>
<ul>
<li><strong>Ans:</strong> Local optima were usually saddle points. SGD performs well because it does not just follow the gradient, so it is likely to fall off a saddle point.</li>
<li><strong>Corrections:</strong> </li>
<li><strong>Review:</strong> <code>loss landscape and convexity, SGD</code> </li>
</ul>
<p>k.</p>
<ul>
<li><strong>Ans:</strong> Depends on the stride and padding. if stride 1 padding 0,  \( 194 \times 194 \times 1\)</li>
<li><strong>Corrections:</strong> </li>
<li><strong>Review:</strong> <code>Convolution reshape equation</code> </li>
</ul>
<p>l.</p>
<ul>
<li><strong>Ans:</strong> They extract features in images. These features can be used for more robust representations of images.</li>
<li><strong>Corrections:</strong> </li>
<li><strong>Review:</strong> <code>Convolutions, Feature Detection</code> </li>
</ul>
<p>m. </p>
<ul>
<li><strong>Ans:</strong> Expectation of dropout is <code>output * p</code>. We can use the expectation of dropout in inference then, but also just use the <code>output</code> by doing dropout at training time (with a mask where each index has probability <code>p</code> being 1 (retained) and dividing by <code>p</code>.</li>
<li><strong>Corrections:</strong> </li>
<li><strong>Review:</strong> <code>Dropout</code></li>
</ul>
<p>n. </p>
<ul>
<li><strong>Ans:</strong> Prediction Averaging reduces variance. Each model is robust to different relationships (learn different things). Parameter averaging canceling out the relationships each model learns. Snapshot parameter ensembling works because the relationships the model was learning are close to the same, while still reducing variance.</li>
<li><strong>Corrections:</strong> </li>
<li><strong>Review:</strong> <code>Prediction Averaging, Parameter Averaging, Snapshot Ensembling</code></li>
</ul>
<p>o. </p>
<ul>
<li><strong>Ans:</strong> x -&gt; [] (array with h wraps into block) -&gt; y</li>
<li><strong>Corrections:</strong> </li>
<li><strong>Review:</strong> <code>RNN</code></li>
</ul>
<p>p. </p>
<ul>
<li><strong>Ans:</strong> <code>y = A_yh * tanh(A_hx * x + A_hh * h)</code></li>
<li><strong>Corrections:</strong> </li>
<li><strong>Review:</strong> <code>RNN equation</code></li>
</ul>
<p>q. </p>
<ul>
<li><strong>Ans:</strong> Remember and Forget?</li>
<li><strong>Corrections:</strong> </li>
<li><strong>Review:</strong> <code>LSTM equation and interpretation</code></li>
</ul>
</li>
</ol>
<h1><a class="header" href="#midterm-1-cheat-sheet" id="midterm-1-cheat-sheet">Midterm 1 Cheat Sheet</a></h1>
<p><img src="https://i.imgur.com/5fKIV3n.jpg" alt="" /></p>
<p><img src="https://i.imgur.com/Ch56t9P.jpg" alt="" /></p>
<h1><a class="header" href="#take-home-quiz-1" id="take-home-quiz-1">Take Home Quiz 1</a></h1>
<h2><a class="header" href="#up-to-3-30-20" id="up-to-3-30-20">Up to 3-30-20</a></h2>
<ul>
<li>Attention Neural Networks</li>
<li>Semantic models for Text</li>
<li>Natural Language Translation and Transformers</li>
<li>Pretraining Language Models</li>
<li>Dialog and other Applications</li>
<li>Generative Models</li>
<li>Generative Adversarial Networks</li>
<li>Adversarial and Fooling Networks</li>
</ul>
<h2><a class="header" href="#from-3-30-20" id="from-3-30-20">From 3-30-20</a></h2>
<ul>
<li>Fairness in Deep Networks</li>
<li>Imitation Learning</li>
<li>Reinforcement Learning: Policy Gradients</li>
<li>Reinforcement Learning: Value-based methods</li>
<li>Exploration</li>
<li>Learning to Learn</li>
<li>
<ul>
<li>Others</li>
</ul>
</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        
        
        
        <script type="text/javascript">
            window.playpen_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
        
        

    </body>
</html>
